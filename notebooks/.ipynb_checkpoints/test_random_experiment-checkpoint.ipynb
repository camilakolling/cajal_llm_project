{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9974afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7ddbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/BRAIN/neuroai_project/work/cajal_llm_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_path = \"/BRAIN/neuroai_project/work/cajal_llm_project\"\n",
    "code_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc3cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed for pearson_correlation function.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(code_path)\n",
    "\n",
    "from encoding import *\n",
    "from preprocessing import get_ordered_representations, normalize_train_test, concat_past_features, lanczosinterp2D, delete_block_edges\n",
    "from encoding import nested_blocked_cv, ridge_regression_fit_sklearn, ridge_regression_predict_torch\n",
    "from analysis import pearson_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c369f",
   "metadata": {},
   "source": [
    "## 0. load fmri data and annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43058c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_prefix = os.path.join(code_path, \"data/HP_data/fMRI\")\n",
    "HF_home = \"/SWS/llms/nobackup/\"\n",
    "results_path_prefix = os.path.join(code_path, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e0b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1211, 25263),\n",
       " array([[-1.39391795e+00, -4.95610000e-01, -1.76625698e+00, ...,\n",
       "         -7.66158058e-01, -2.32445619e-01, -1.46871563e-01],\n",
       "        [ 5.30454149e-01, -2.32485978e-01,  3.52580458e-01, ...,\n",
       "         -2.31855518e-03, -2.46482123e-01, -4.29284279e-01],\n",
       "        [ 1.13308842e+00,  3.31803866e-01, -3.14589030e-01, ...,\n",
       "          8.15993870e-01,  1.31184511e+00,  1.38407545e+00],\n",
       "        ...,\n",
       "        [-1.10624234e+00, -1.08674185e+00, -5.44766153e-01, ...,\n",
       "          6.70158027e-01,  9.81612876e-01,  8.54572439e-01],\n",
       "        [-1.58241086e+00, -1.14630569e+00, -5.57836731e-01, ...,\n",
       "         -3.30246991e-01, -4.22094739e-01, -1.26951335e-01],\n",
       "        [-2.59743061e+00, -1.55403741e+00, -1.93496114e+00, ...,\n",
       "          1.01716606e+00,  2.10392591e-01,  1.11087041e-01]],\n",
       "       shape=(10, 25263)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw fmri data for one subject\n",
    "fmri_data = np.load(f\"{data_path_prefix}/data_subject_I.npy\", allow_pickle=True)\n",
    "fmri_data.shape, fmri_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3653a9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1351,), array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18], dtype=uint16))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing of each fmri TRs in seconds\n",
    "fmri_time = np.load(f\"{data_path_prefix}/time_fmri.npy\", allow_pickle=True)\n",
    "fmri_time.shape, fmri_time[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd0705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1351,), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of which TRs belong to which run.\n",
    "fmri_runs = np.load(f\"{data_path_prefix}/runs_fmri.npy\", allow_pickle=True)\n",
    "fmri_runs.shape, fmri_runs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a8f787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5176,),\n",
       " array(['Harry', 'had', 'never', 'believed', 'he', 'would', 'meet', 'a',\n",
       "        'boy', 'he'], dtype='<U14'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of words shown as stimuli (sequentially on a screen word by word)\n",
    "stimuli_words = np.load(f\"{data_path_prefix}/words_fmri.npy\", allow_pickle=True)\n",
    "stimuli_words.shape, stimuli_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff584548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\" \".join(stimuli_words).split(\"+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8946f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5176,), array([20. , 20.5, 21. , 21.5, 22. , 22.5, 23. , 23.5, 24. , 24.5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing in seconds of the words\n",
    "word_times = np.load(f\"{data_path_prefix}/time_words_fmri.npy\", allow_pickle=True)\n",
    "word_times.shape, word_times[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83b992",
   "metadata": {},
   "source": [
    "## 1. prepare the input sequence for the LLM\n",
    "(e.g. by changing formatting). Here we change \"+\" to \"\\n\\n\" and \"@\" to nothing (used to highlight italics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aeb6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_input_sequence = []\n",
    "for word in stimuli_words:\n",
    "    LLM_input_sequence.append(word) if word != \"+\" and not \"@\" in word \\\n",
    "    else LLM_input_sequence.append(word.replace(\"+\", \"\\n\\n\").replace(\"@\",\"\"))\n",
    "assert len(word_times.tolist()) == len(LLM_input_sequence), \"different length\" # make sure we still have the same length as we have word timings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5517a",
   "metadata": {},
   "source": [
    "### Shuffling words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd7739c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.str_('Harry'),\n",
       " np.str_('had'),\n",
       " np.str_('never'),\n",
       " np.str_('believed'),\n",
       " np.str_('he'),\n",
       " np.str_('would'),\n",
       " np.str_('meet'),\n",
       " np.str_('a'),\n",
       " np.str_('boy'),\n",
       " np.str_('he'),\n",
       " np.str_('hated'),\n",
       " np.str_('more'),\n",
       " np.str_('than'),\n",
       " np.str_('Dudley,'),\n",
       " np.str_('but'),\n",
       " np.str_('that'),\n",
       " np.str_('was'),\n",
       " np.str_('before'),\n",
       " np.str_('he'),\n",
       " np.str_('met'),\n",
       " np.str_('Draco'),\n",
       " np.str_('Malfoy.'),\n",
       " np.str_('Still,'),\n",
       " np.str_('first-year'),\n",
       " np.str_('Gryffindors'),\n",
       " np.str_('only'),\n",
       " np.str_('had'),\n",
       " np.str_('Potions'),\n",
       " np.str_('with'),\n",
       " np.str_('the'),\n",
       " np.str_('Slytherins,'),\n",
       " np.str_('so'),\n",
       " np.str_('they'),\n",
       " np.str_(\"didn't\"),\n",
       " np.str_('have'),\n",
       " np.str_('to'),\n",
       " np.str_('put'),\n",
       " np.str_('up'),\n",
       " np.str_('with'),\n",
       " np.str_('Malfoy'),\n",
       " np.str_('much.'),\n",
       " np.str_('Or'),\n",
       " np.str_('at'),\n",
       " np.str_('least,'),\n",
       " np.str_('they'),\n",
       " np.str_(\"didn't\"),\n",
       " np.str_('until'),\n",
       " np.str_('they'),\n",
       " np.str_('spotted'),\n",
       " np.str_('a'),\n",
       " np.str_('notice'),\n",
       " np.str_('pinned'),\n",
       " np.str_('up'),\n",
       " np.str_('in'),\n",
       " np.str_('the'),\n",
       " np.str_('Gryffindor'),\n",
       " np.str_('common'),\n",
       " np.str_('room'),\n",
       " np.str_('that'),\n",
       " np.str_('made'),\n",
       " np.str_('them'),\n",
       " np.str_('all'),\n",
       " np.str_('groan.'),\n",
       " np.str_('Flying'),\n",
       " np.str_('lessons'),\n",
       " np.str_('would'),\n",
       " np.str_('be'),\n",
       " np.str_('starting'),\n",
       " np.str_('on'),\n",
       " np.str_('Thursday'),\n",
       " np.str_('--'),\n",
       " np.str_('and'),\n",
       " np.str_('Gryffindor'),\n",
       " np.str_('and'),\n",
       " np.str_('Slytherin'),\n",
       " np.str_('would'),\n",
       " np.str_('be'),\n",
       " np.str_('learning'),\n",
       " np.str_('together.'),\n",
       " '\\n\\n',\n",
       " np.str_('\"Typical,\"'),\n",
       " np.str_('said'),\n",
       " np.str_('Harry'),\n",
       " np.str_('darkly.'),\n",
       " np.str_('\"Just'),\n",
       " np.str_('what'),\n",
       " np.str_('I'),\n",
       " np.str_('always'),\n",
       " np.str_('wanted.'),\n",
       " np.str_('To'),\n",
       " np.str_('make'),\n",
       " np.str_('a'),\n",
       " np.str_('fool'),\n",
       " np.str_('of'),\n",
       " np.str_('myself'),\n",
       " np.str_('on'),\n",
       " np.str_('a'),\n",
       " np.str_('broomstick'),\n",
       " np.str_('in'),\n",
       " np.str_('front'),\n",
       " np.str_('of'),\n",
       " np.str_('Malfoy.\"'),\n",
       " '\\n\\n',\n",
       " np.str_('He'),\n",
       " np.str_('had'),\n",
       " np.str_('been'),\n",
       " np.str_('looking'),\n",
       " np.str_('forward'),\n",
       " np.str_('to'),\n",
       " np.str_('learning'),\n",
       " np.str_('to'),\n",
       " np.str_('fly'),\n",
       " np.str_('more'),\n",
       " np.str_('than'),\n",
       " np.str_('anything'),\n",
       " np.str_('else.'),\n",
       " np.str_('\"You'),\n",
       " np.str_(\"don't\"),\n",
       " np.str_('know'),\n",
       " np.str_('that'),\n",
       " np.str_(\"you'll\"),\n",
       " np.str_('make'),\n",
       " np.str_('a'),\n",
       " np.str_('fool'),\n",
       " np.str_('of'),\n",
       " np.str_('yourself,\"'),\n",
       " np.str_('said'),\n",
       " np.str_('Ron'),\n",
       " np.str_('reasonably.'),\n",
       " np.str_('\"Anyway,'),\n",
       " np.str_('I'),\n",
       " np.str_('know'),\n",
       " np.str_(\"Malfoy's\"),\n",
       " np.str_('always'),\n",
       " np.str_('going'),\n",
       " np.str_('on'),\n",
       " np.str_('about'),\n",
       " np.str_('how'),\n",
       " np.str_('good'),\n",
       " np.str_('he'),\n",
       " np.str_('is'),\n",
       " np.str_('at'),\n",
       " np.str_('Quidditch,'),\n",
       " np.str_('but'),\n",
       " np.str_('I'),\n",
       " np.str_('bet'),\n",
       " np.str_(\"that's\"),\n",
       " np.str_('all'),\n",
       " np.str_('talk.\"'),\n",
       " '\\n\\n',\n",
       " np.str_('Malfoy'),\n",
       " np.str_('certainly'),\n",
       " np.str_('did'),\n",
       " np.str_('talk'),\n",
       " np.str_('about'),\n",
       " np.str_('flying'),\n",
       " np.str_('a'),\n",
       " np.str_('lot.'),\n",
       " np.str_('He'),\n",
       " np.str_('complained'),\n",
       " np.str_('loudly'),\n",
       " np.str_('about'),\n",
       " np.str_('first'),\n",
       " np.str_('years'),\n",
       " np.str_('never'),\n",
       " np.str_('getting'),\n",
       " np.str_('on'),\n",
       " np.str_('the'),\n",
       " np.str_('House'),\n",
       " np.str_('Quidditch'),\n",
       " np.str_('teams'),\n",
       " np.str_('and'),\n",
       " np.str_('told'),\n",
       " np.str_('long,'),\n",
       " np.str_('boastful'),\n",
       " np.str_('stories'),\n",
       " np.str_('that'),\n",
       " np.str_('always'),\n",
       " np.str_('seemed'),\n",
       " np.str_('to'),\n",
       " np.str_('end'),\n",
       " np.str_('with'),\n",
       " np.str_('him'),\n",
       " np.str_('narrowly'),\n",
       " np.str_('escaping'),\n",
       " np.str_('Muggles'),\n",
       " np.str_('in'),\n",
       " np.str_('helicopters.'),\n",
       " np.str_('He'),\n",
       " np.str_(\"wasn't\"),\n",
       " np.str_('the'),\n",
       " np.str_('only'),\n",
       " np.str_('one,'),\n",
       " np.str_('though:'),\n",
       " np.str_('the'),\n",
       " np.str_('way'),\n",
       " np.str_('Seamus'),\n",
       " np.str_('Finnigan'),\n",
       " np.str_('told'),\n",
       " np.str_('it,'),\n",
       " np.str_(\"he'd\"),\n",
       " np.str_('spent'),\n",
       " np.str_('most'),\n",
       " np.str_('of'),\n",
       " np.str_('his'),\n",
       " np.str_('childhood'),\n",
       " np.str_('zooming'),\n",
       " np.str_('around'),\n",
       " np.str_('the'),\n",
       " np.str_('countryside'),\n",
       " np.str_('on'),\n",
       " np.str_('his'),\n",
       " np.str_('broomstick.'),\n",
       " np.str_('Even'),\n",
       " np.str_('Ron'),\n",
       " np.str_('would'),\n",
       " np.str_('tell'),\n",
       " np.str_('anyone'),\n",
       " np.str_(\"who'd\"),\n",
       " np.str_('listen'),\n",
       " np.str_('about'),\n",
       " np.str_('the'),\n",
       " np.str_('time'),\n",
       " np.str_(\"he'd\"),\n",
       " np.str_('almost'),\n",
       " np.str_('hit'),\n",
       " np.str_('a'),\n",
       " np.str_('hang'),\n",
       " np.str_('glider'),\n",
       " np.str_('on'),\n",
       " np.str_(\"Charlie's\"),\n",
       " np.str_('old'),\n",
       " np.str_('broom.'),\n",
       " np.str_('Everyone'),\n",
       " np.str_('from'),\n",
       " np.str_('wizarding'),\n",
       " np.str_('families'),\n",
       " np.str_('talked'),\n",
       " np.str_('about'),\n",
       " np.str_('Quidditch'),\n",
       " np.str_('constantly.'),\n",
       " np.str_('Ron'),\n",
       " np.str_('had'),\n",
       " np.str_('already'),\n",
       " np.str_('had'),\n",
       " np.str_('a'),\n",
       " np.str_('big'),\n",
       " np.str_('argument'),\n",
       " np.str_('with'),\n",
       " np.str_('Dean'),\n",
       " np.str_('Thomas,'),\n",
       " np.str_('who'),\n",
       " np.str_('shared'),\n",
       " np.str_('their'),\n",
       " np.str_('dormitory,'),\n",
       " np.str_('about'),\n",
       " np.str_('soccer.'),\n",
       " np.str_('Ron'),\n",
       " np.str_(\"couldn't\"),\n",
       " np.str_('see'),\n",
       " np.str_('what'),\n",
       " np.str_('was'),\n",
       " np.str_('exciting'),\n",
       " np.str_('about'),\n",
       " np.str_('a'),\n",
       " np.str_('game'),\n",
       " np.str_('with'),\n",
       " np.str_('only'),\n",
       " np.str_('one'),\n",
       " np.str_('ball'),\n",
       " np.str_('where'),\n",
       " np.str_('no'),\n",
       " np.str_('one'),\n",
       " np.str_('was'),\n",
       " np.str_('allowed'),\n",
       " np.str_('to'),\n",
       " np.str_('fly.'),\n",
       " np.str_('Harry'),\n",
       " np.str_('had'),\n",
       " np.str_('caught'),\n",
       " np.str_('Ron'),\n",
       " np.str_('prodding'),\n",
       " np.str_(\"Dean's\"),\n",
       " np.str_('poster'),\n",
       " np.str_('of'),\n",
       " np.str_('West'),\n",
       " np.str_('Ham'),\n",
       " np.str_('soccer'),\n",
       " np.str_('team,'),\n",
       " np.str_('trying'),\n",
       " np.str_('to'),\n",
       " np.str_('make'),\n",
       " np.str_('the'),\n",
       " np.str_('players'),\n",
       " np.str_('move.'),\n",
       " '\\n\\n',\n",
       " np.str_('Neville'),\n",
       " np.str_('had'),\n",
       " np.str_('never'),\n",
       " np.str_('been'),\n",
       " np.str_('on'),\n",
       " np.str_('a'),\n",
       " np.str_('broomstick'),\n",
       " np.str_('in'),\n",
       " np.str_('his'),\n",
       " np.str_('life,'),\n",
       " np.str_('because'),\n",
       " np.str_('his'),\n",
       " np.str_('grandmother'),\n",
       " np.str_('had'),\n",
       " np.str_('never'),\n",
       " np.str_('let'),\n",
       " np.str_('him'),\n",
       " np.str_('near'),\n",
       " np.str_('one.'),\n",
       " np.str_('Privately,'),\n",
       " np.str_('Harry'),\n",
       " np.str_('felt'),\n",
       " np.str_(\"she'd\"),\n",
       " np.str_('had'),\n",
       " np.str_('good'),\n",
       " np.str_('reason,'),\n",
       " np.str_('because'),\n",
       " np.str_('Neville'),\n",
       " np.str_('managed'),\n",
       " np.str_('to'),\n",
       " np.str_('have'),\n",
       " np.str_('an'),\n",
       " np.str_('extraordinary'),\n",
       " np.str_('number'),\n",
       " np.str_('of'),\n",
       " np.str_('accidents'),\n",
       " np.str_('even'),\n",
       " np.str_('with'),\n",
       " np.str_('both'),\n",
       " np.str_('feet'),\n",
       " np.str_('on'),\n",
       " np.str_('the'),\n",
       " np.str_('ground.'),\n",
       " '\\n\\n',\n",
       " np.str_('Hermione'),\n",
       " np.str_('Granger'),\n",
       " np.str_('was'),\n",
       " np.str_('almost'),\n",
       " np.str_('as'),\n",
       " np.str_('nervous'),\n",
       " np.str_('about'),\n",
       " np.str_('flying'),\n",
       " np.str_('as'),\n",
       " np.str_('Neville'),\n",
       " np.str_('was.'),\n",
       " np.str_('This'),\n",
       " np.str_('was'),\n",
       " np.str_('something'),\n",
       " np.str_('you'),\n",
       " np.str_(\"couldn't\"),\n",
       " np.str_('learn'),\n",
       " np.str_('by'),\n",
       " np.str_('heart'),\n",
       " np.str_('out'),\n",
       " np.str_('of'),\n",
       " np.str_('a'),\n",
       " np.str_('book'),\n",
       " np.str_('--'),\n",
       " np.str_('not'),\n",
       " np.str_('that'),\n",
       " np.str_('she'),\n",
       " np.str_(\"hadn't\"),\n",
       " np.str_('tried.'),\n",
       " np.str_('At'),\n",
       " np.str_('breakfast'),\n",
       " np.str_('on'),\n",
       " np.str_('Thursday'),\n",
       " np.str_('she'),\n",
       " np.str_('bored'),\n",
       " np.str_('them'),\n",
       " np.str_('all'),\n",
       " np.str_('stupid'),\n",
       " np.str_('with'),\n",
       " np.str_('flying'),\n",
       " np.str_('tips'),\n",
       " np.str_(\"she'd\"),\n",
       " np.str_('gotten'),\n",
       " np.str_('out'),\n",
       " np.str_('of'),\n",
       " np.str_('a'),\n",
       " np.str_('library'),\n",
       " np.str_('book'),\n",
       " np.str_('called'),\n",
       " 'Quidditch',\n",
       " 'Through',\n",
       " 'the',\n",
       " 'Ages.',\n",
       " np.str_('Neville'),\n",
       " np.str_('was'),\n",
       " np.str_('hanging'),\n",
       " np.str_('on'),\n",
       " np.str_('to'),\n",
       " np.str_('her'),\n",
       " np.str_('every'),\n",
       " np.str_('word,'),\n",
       " np.str_('desperate'),\n",
       " np.str_('for'),\n",
       " np.str_('anything'),\n",
       " np.str_('that'),\n",
       " np.str_('might'),\n",
       " np.str_('help'),\n",
       " np.str_('him'),\n",
       " np.str_('hang'),\n",
       " np.str_('on'),\n",
       " np.str_('to'),\n",
       " np.str_('his'),\n",
       " np.str_('broomstick'),\n",
       " np.str_('later,'),\n",
       " np.str_('but'),\n",
       " np.str_('everybody'),\n",
       " np.str_('else'),\n",
       " np.str_('was'),\n",
       " np.str_('very'),\n",
       " np.str_('pleased'),\n",
       " np.str_('when'),\n",
       " np.str_(\"Hermione's\"),\n",
       " np.str_('lecture'),\n",
       " np.str_('was'),\n",
       " np.str_('interrupted'),\n",
       " np.str_('by'),\n",
       " np.str_('the'),\n",
       " np.str_('arrival'),\n",
       " np.str_('of'),\n",
       " np.str_('the'),\n",
       " np.str_('mail.'),\n",
       " '\\n\\n',\n",
       " np.str_('Harry'),\n",
       " np.str_(\"hadn't\"),\n",
       " np.str_('had'),\n",
       " np.str_('a'),\n",
       " np.str_('single'),\n",
       " np.str_('letter'),\n",
       " np.str_('since'),\n",
       " np.str_(\"Hagrid's\"),\n",
       " np.str_('note,'),\n",
       " np.str_('something'),\n",
       " np.str_('that'),\n",
       " np.str_('Malfoy'),\n",
       " np.str_('had'),\n",
       " np.str_('been'),\n",
       " np.str_('quick'),\n",
       " np.str_('to'),\n",
       " np.str_('notice,'),\n",
       " np.str_('of'),\n",
       " np.str_('course.'),\n",
       " np.str_(\"Malfoy's\"),\n",
       " np.str_('eagle'),\n",
       " np.str_('owl'),\n",
       " np.str_('was'),\n",
       " np.str_('always'),\n",
       " np.str_('bringing'),\n",
       " np.str_('him'),\n",
       " np.str_('packages'),\n",
       " np.str_('of'),\n",
       " np.str_('sweets'),\n",
       " np.str_('from'),\n",
       " np.str_('home,'),\n",
       " np.str_('which'),\n",
       " np.str_('he'),\n",
       " np.str_('opened'),\n",
       " np.str_('gloatingly'),\n",
       " np.str_('at'),\n",
       " np.str_('the'),\n",
       " np.str_('Slytherin'),\n",
       " np.str_('table.'),\n",
       " '\\n\\n',\n",
       " np.str_('A'),\n",
       " np.str_('barn'),\n",
       " np.str_('owl'),\n",
       " np.str_('brought'),\n",
       " np.str_('Neville'),\n",
       " np.str_('a'),\n",
       " np.str_('small'),\n",
       " np.str_('package'),\n",
       " np.str_('from'),\n",
       " np.str_('his'),\n",
       " np.str_('grandmother.'),\n",
       " np.str_('He'),\n",
       " np.str_('opened'),\n",
       " np.str_('it'),\n",
       " np.str_('excitedly'),\n",
       " np.str_('and'),\n",
       " np.str_('showed'),\n",
       " np.str_('them'),\n",
       " np.str_('a'),\n",
       " np.str_('glass'),\n",
       " np.str_('ball'),\n",
       " np.str_('the'),\n",
       " np.str_('size'),\n",
       " np.str_('of'),\n",
       " np.str_('a'),\n",
       " np.str_('large'),\n",
       " np.str_('marble,'),\n",
       " np.str_('which'),\n",
       " np.str_('seemed'),\n",
       " np.str_('to'),\n",
       " np.str_('be'),\n",
       " np.str_('full'),\n",
       " np.str_('of'),\n",
       " np.str_('white'),\n",
       " np.str_('smoke.'),\n",
       " '\\n\\n',\n",
       " np.str_('\"It\\'s'),\n",
       " np.str_('a'),\n",
       " np.str_('Remembrall!\"'),\n",
       " np.str_('he'),\n",
       " np.str_('explained.'),\n",
       " np.str_('\"Gran'),\n",
       " np.str_('knows'),\n",
       " np.str_('I'),\n",
       " np.str_('forget'),\n",
       " np.str_('things'),\n",
       " np.str_('--'),\n",
       " np.str_('this'),\n",
       " np.str_('tells'),\n",
       " np.str_('you'),\n",
       " np.str_('if'),\n",
       " np.str_(\"there's\"),\n",
       " np.str_('something'),\n",
       " np.str_(\"you've\"),\n",
       " np.str_('forgotten'),\n",
       " np.str_('to'),\n",
       " np.str_('do.'),\n",
       " np.str_('Look,'),\n",
       " np.str_('you'),\n",
       " np.str_('hold'),\n",
       " np.str_('it'),\n",
       " np.str_('tight'),\n",
       " np.str_('like'),\n",
       " np.str_('this'),\n",
       " np.str_('and'),\n",
       " np.str_('if'),\n",
       " np.str_('it'),\n",
       " np.str_('turns'),\n",
       " np.str_('red'),\n",
       " np.str_('--'),\n",
       " np.str_('oh'),\n",
       " np.str_('…\"'),\n",
       " np.str_('His'),\n",
       " np.str_('face'),\n",
       " np.str_('fell,'),\n",
       " np.str_('because'),\n",
       " np.str_('the'),\n",
       " np.str_('Remembrall'),\n",
       " np.str_('had'),\n",
       " np.str_('suddenly'),\n",
       " np.str_('glowed'),\n",
       " np.str_('scarlet,'),\n",
       " np.str_('\"…'),\n",
       " np.str_(\"you've\"),\n",
       " np.str_('forgotten'),\n",
       " np.str_('something'),\n",
       " np.str_('…\"'),\n",
       " '\\n\\n',\n",
       " np.str_('Neville'),\n",
       " np.str_('was'),\n",
       " np.str_('trying'),\n",
       " np.str_('to'),\n",
       " np.str_('remember'),\n",
       " np.str_('what'),\n",
       " np.str_(\"he'd\"),\n",
       " np.str_('forgotten'),\n",
       " np.str_('when'),\n",
       " np.str_('Draco'),\n",
       " np.str_('Malfoy,'),\n",
       " np.str_('who'),\n",
       " np.str_('was'),\n",
       " np.str_('passing'),\n",
       " np.str_('the'),\n",
       " np.str_('Gryffindor'),\n",
       " np.str_('table,'),\n",
       " np.str_('snatched'),\n",
       " np.str_('the'),\n",
       " np.str_('Remembrall'),\n",
       " np.str_('out'),\n",
       " np.str_('of'),\n",
       " np.str_('his'),\n",
       " np.str_('hand.'),\n",
       " '\\n\\n',\n",
       " np.str_('Harry'),\n",
       " np.str_('and'),\n",
       " np.str_('Ron'),\n",
       " np.str_('jumped'),\n",
       " np.str_('to'),\n",
       " np.str_('their'),\n",
       " np.str_('feet.'),\n",
       " np.str_('They'),\n",
       " np.str_('were'),\n",
       " np.str_('half'),\n",
       " np.str_('hoping'),\n",
       " np.str_('for'),\n",
       " np.str_('a'),\n",
       " np.str_('reason'),\n",
       " np.str_('to'),\n",
       " np.str_('fight'),\n",
       " np.str_('Malfoy,'),\n",
       " np.str_('but'),\n",
       " np.str_('Professor'),\n",
       " np.str_('McGonagall,'),\n",
       " np.str_('who'),\n",
       " np.str_('could'),\n",
       " np.str_('spot'),\n",
       " np.str_('trouble'),\n",
       " np.str_('quicker'),\n",
       " np.str_('than'),\n",
       " np.str_('any'),\n",
       " np.str_('teacher'),\n",
       " np.str_('in'),\n",
       " np.str_('the'),\n",
       " np.str_('school,'),\n",
       " np.str_('was'),\n",
       " np.str_('there'),\n",
       " np.str_('in'),\n",
       " np.str_('a'),\n",
       " np.str_('flash.'),\n",
       " '\\n\\n',\n",
       " np.str_('\"What\\'s'),\n",
       " np.str_('going'),\n",
       " np.str_('on?\"'),\n",
       " '\\n\\n',\n",
       " np.str_('\"Malfoy\\'s'),\n",
       " np.str_('got'),\n",
       " np.str_('my'),\n",
       " np.str_('Remembrall,'),\n",
       " np.str_('Professor.\"'),\n",
       " '\\n\\n',\n",
       " np.str_('Scowling,'),\n",
       " np.str_('Malfoy'),\n",
       " np.str_('quickly'),\n",
       " np.str_('dropped'),\n",
       " np.str_('the'),\n",
       " np.str_('Remembrall'),\n",
       " np.str_('back'),\n",
       " np.str_('on'),\n",
       " np.str_('the'),\n",
       " np.str_('table.'),\n",
       " '\\n\\n',\n",
       " np.str_('\"Just'),\n",
       " np.str_('looking,\"'),\n",
       " np.str_('he'),\n",
       " np.str_('said,'),\n",
       " np.str_('and'),\n",
       " np.str_('he'),\n",
       " np.str_('sloped'),\n",
       " np.str_('away'),\n",
       " np.str_('with'),\n",
       " np.str_('Crabbe'),\n",
       " np.str_('and'),\n",
       " np.str_('Goyle'),\n",
       " np.str_('behind'),\n",
       " np.str_('him.'),\n",
       " '\\n\\n',\n",
       " '\\n\\n',\n",
       " np.str_('At'),\n",
       " np.str_('three-thirty'),\n",
       " np.str_('that'),\n",
       " np.str_('afternoon,'),\n",
       " np.str_('Harry,'),\n",
       " np.str_('Ron,'),\n",
       " np.str_('and'),\n",
       " np.str_('the'),\n",
       " np.str_('other'),\n",
       " np.str_('Gryffindors'),\n",
       " np.str_('hurried'),\n",
       " np.str_('down'),\n",
       " np.str_('the'),\n",
       " np.str_('front'),\n",
       " np.str_('steps'),\n",
       " np.str_('onto'),\n",
       " np.str_('the'),\n",
       " np.str_('grounds'),\n",
       " np.str_('for'),\n",
       " np.str_('their'),\n",
       " np.str_('first'),\n",
       " np.str_('flying'),\n",
       " np.str_('lesson.'),\n",
       " np.str_('It'),\n",
       " np.str_('was'),\n",
       " np.str_('a'),\n",
       " np.str_('clear,'),\n",
       " np.str_('breezy'),\n",
       " np.str_('day,'),\n",
       " np.str_('and'),\n",
       " np.str_('the'),\n",
       " np.str_('grass'),\n",
       " np.str_('rippled'),\n",
       " np.str_('under'),\n",
       " np.str_('their'),\n",
       " np.str_('feet'),\n",
       " np.str_('as'),\n",
       " np.str_('they'),\n",
       " np.str_('marched'),\n",
       " np.str_('down'),\n",
       " np.str_('the'),\n",
       " np.str_('sloping'),\n",
       " np.str_('lawns'),\n",
       " np.str_('toward'),\n",
       " np.str_('a'),\n",
       " np.str_('smooth,'),\n",
       " np.str_('flat'),\n",
       " np.str_('lawn'),\n",
       " np.str_('on'),\n",
       " np.str_('the'),\n",
       " np.str_('opposite'),\n",
       " np.str_('side'),\n",
       " np.str_('of'),\n",
       " np.str_('the'),\n",
       " np.str_('grounds'),\n",
       " np.str_('to'),\n",
       " np.str_('the'),\n",
       " np.str_('forbidden'),\n",
       " np.str_('forest,'),\n",
       " np.str_('whose'),\n",
       " np.str_('trees'),\n",
       " np.str_('were'),\n",
       " np.str_('swaying'),\n",
       " np.str_('darkly'),\n",
       " np.str_('in'),\n",
       " np.str_('the'),\n",
       " np.str_('distance.'),\n",
       " '\\n\\n',\n",
       " np.str_('The'),\n",
       " np.str_('Slytherins'),\n",
       " np.str_('were'),\n",
       " np.str_('already'),\n",
       " np.str_('there,'),\n",
       " np.str_('and'),\n",
       " np.str_('so'),\n",
       " np.str_('were'),\n",
       " np.str_('twenty'),\n",
       " np.str_('broomsticks'),\n",
       " np.str_('lying'),\n",
       " np.str_('in'),\n",
       " np.str_('neat'),\n",
       " np.str_('lines'),\n",
       " np.str_('on'),\n",
       " np.str_('the'),\n",
       " np.str_('ground.'),\n",
       " np.str_('Harry'),\n",
       " np.str_('had'),\n",
       " np.str_('heard'),\n",
       " np.str_('Fred'),\n",
       " np.str_('and'),\n",
       " np.str_('George'),\n",
       " np.str_('Weasley'),\n",
       " np.str_('complain'),\n",
       " np.str_('about'),\n",
       " np.str_('the'),\n",
       " np.str_('school'),\n",
       " np.str_('brooms,'),\n",
       " np.str_('saying'),\n",
       " np.str_('that'),\n",
       " np.str_('some'),\n",
       " np.str_('of'),\n",
       " np.str_('them'),\n",
       " np.str_('started'),\n",
       " np.str_('to'),\n",
       " np.str_('vibrate'),\n",
       " np.str_('if'),\n",
       " np.str_('you'),\n",
       " np.str_('flew'),\n",
       " np.str_('too'),\n",
       " np.str_('high,'),\n",
       " np.str_('or'),\n",
       " np.str_('always'),\n",
       " np.str_('flew'),\n",
       " np.str_('slightly'),\n",
       " np.str_('to'),\n",
       " np.str_('the'),\n",
       " np.str_('left.'),\n",
       " '\\n\\n',\n",
       " np.str_('Their'),\n",
       " np.str_('teacher,'),\n",
       " np.str_('Madam'),\n",
       " np.str_('Hooch,'),\n",
       " np.str_('arrived.'),\n",
       " np.str_('She'),\n",
       " np.str_('had'),\n",
       " np.str_('short,'),\n",
       " np.str_('gray'),\n",
       " np.str_('hair,'),\n",
       " np.str_('and'),\n",
       " np.str_('yellow'),\n",
       " np.str_('eyes'),\n",
       " np.str_('like'),\n",
       " np.str_('a'),\n",
       " np.str_('hawk.'),\n",
       " '\\n\\n',\n",
       " np.str_('\"Well,'),\n",
       " np.str_('what'),\n",
       " np.str_('are'),\n",
       " np.str_('you'),\n",
       " np.str_('all'),\n",
       " np.str_('waiting'),\n",
       " np.str_('for?\"'),\n",
       " np.str_('she'),\n",
       " np.str_('barked.'),\n",
       " np.str_('\"Everyone'),\n",
       " np.str_('stand'),\n",
       " np.str_('by'),\n",
       " np.str_('a'),\n",
       " np.str_('broomstick.'),\n",
       " np.str_('Come'),\n",
       " np.str_('on,'),\n",
       " np.str_('hurry'),\n",
       " np.str_('up.\"'),\n",
       " '\\n\\n',\n",
       " np.str_('Harry'),\n",
       " np.str_('glanced'),\n",
       " np.str_('down'),\n",
       " np.str_('at'),\n",
       " np.str_('his'),\n",
       " np.str_('broom.'),\n",
       " np.str_('It'),\n",
       " np.str_('was'),\n",
       " np.str_('old'),\n",
       " np.str_('and'),\n",
       " np.str_('some'),\n",
       " np.str_('of'),\n",
       " np.str_('the'),\n",
       " np.str_('twigs'),\n",
       " np.str_('stuck'),\n",
       " np.str_('out'),\n",
       " np.str_('at'),\n",
       " np.str_('odd'),\n",
       " np.str_('angles.'),\n",
       " '\\n\\n',\n",
       " np.str_('\"Stick'),\n",
       " np.str_('out'),\n",
       " np.str_('your'),\n",
       " np.str_('right'),\n",
       " np.str_('hand'),\n",
       " np.str_('over'),\n",
       " np.str_('your'),\n",
       " np.str_('broom,\"'),\n",
       " np.str_('called'),\n",
       " np.str_('Madam'),\n",
       " np.str_('Hooch'),\n",
       " np.str_('at'),\n",
       " np.str_('the'),\n",
       " np.str_('front,'),\n",
       " np.str_('\"and'),\n",
       " np.str_('say'),\n",
       " np.str_('‘Up!\\'\"'),\n",
       " '\\n\\n',\n",
       " np.str_('\"UP!\"'),\n",
       " np.str_('everyone'),\n",
       " np.str_('shouted.'),\n",
       " '\\n\\n',\n",
       " np.str_(\"Harry's\"),\n",
       " np.str_('broom'),\n",
       " np.str_('jumped'),\n",
       " np.str_('into'),\n",
       " np.str_('his'),\n",
       " np.str_('hand'),\n",
       " np.str_('at'),\n",
       " np.str_('once,'),\n",
       " np.str_('but'),\n",
       " np.str_('it'),\n",
       " np.str_('was'),\n",
       " np.str_('one'),\n",
       " np.str_('of'),\n",
       " np.str_('the'),\n",
       " np.str_('few'),\n",
       " np.str_('that'),\n",
       " np.str_('did.'),\n",
       " np.str_('Hermione'),\n",
       " np.str_(\"Granger's\"),\n",
       " np.str_('had'),\n",
       " np.str_('simply'),\n",
       " np.str_('rolled'),\n",
       " np.str_('over'),\n",
       " np.str_('on'),\n",
       " np.str_('the'),\n",
       " np.str_('ground,'),\n",
       " np.str_('and'),\n",
       " np.str_(\"Neville's\"),\n",
       " np.str_(\"hadn't\"),\n",
       " np.str_('moved'),\n",
       " np.str_('at'),\n",
       " np.str_('all.'),\n",
       " np.str_('Perhaps'),\n",
       " np.str_('brooms,'),\n",
       " np.str_('like'),\n",
       " np.str_('horses,'),\n",
       " np.str_('could'),\n",
       " np.str_('tell'),\n",
       " np.str_('when'),\n",
       " np.str_('you'),\n",
       " np.str_('were'),\n",
       " np.str_('afraid,'),\n",
       " np.str_('thought'),\n",
       " np.str_('Harry;'),\n",
       " np.str_('there'),\n",
       " np.str_('was'),\n",
       " np.str_('a'),\n",
       " np.str_('quaver'),\n",
       " np.str_('in'),\n",
       " np.str_(\"Neville's\"),\n",
       " np.str_('voice'),\n",
       " np.str_('that'),\n",
       " np.str_('said'),\n",
       " np.str_('only'),\n",
       " np.str_('too'),\n",
       " np.str_('clearly'),\n",
       " np.str_('that'),\n",
       " np.str_('he'),\n",
       " np.str_('wanted'),\n",
       " np.str_('to'),\n",
       " np.str_('keep'),\n",
       " np.str_('his'),\n",
       " np.str_('feet'),\n",
       " np.str_('on'),\n",
       " np.str_('the'),\n",
       " np.str_('ground.'),\n",
       " '\\n\\n',\n",
       " np.str_('Madam'),\n",
       " np.str_('Hooch'),\n",
       " np.str_('then'),\n",
       " np.str_('showed'),\n",
       " np.str_('them'),\n",
       " np.str_('how'),\n",
       " np.str_('to'),\n",
       " np.str_('mount'),\n",
       " np.str_('their'),\n",
       " np.str_('brooms'),\n",
       " np.str_('without'),\n",
       " np.str_('sliding'),\n",
       " np.str_('off'),\n",
       " np.str_('the'),\n",
       " np.str_('end,'),\n",
       " np.str_('and'),\n",
       " np.str_('walked'),\n",
       " np.str_('up'),\n",
       " np.str_('and'),\n",
       " np.str_('down'),\n",
       " np.str_('the'),\n",
       " np.str_('rows'),\n",
       " np.str_('correcting'),\n",
       " np.str_('their'),\n",
       " np.str_('grips.'),\n",
       " np.str_('Harry'),\n",
       " np.str_('and'),\n",
       " np.str_('Ron'),\n",
       " np.str_('were'),\n",
       " np.str_('delighted'),\n",
       " np.str_('when'),\n",
       " np.str_('she'),\n",
       " np.str_('told'),\n",
       " np.str_('Malfoy'),\n",
       " np.str_(\"he'd\"),\n",
       " np.str_('been'),\n",
       " np.str_('doing'),\n",
       " np.str_('it'),\n",
       " np.str_('wrong'),\n",
       " np.str_('for'),\n",
       " np.str_('years.'),\n",
       " '\\n\\n',\n",
       " np.str_('\"Now,'),\n",
       " np.str_('when'),\n",
       " np.str_('I'),\n",
       " np.str_('blow'),\n",
       " np.str_('my'),\n",
       " np.str_('whistle,'),\n",
       " np.str_('you'),\n",
       " np.str_('kick'),\n",
       " np.str_('off'),\n",
       " np.str_('from'),\n",
       " np.str_('the'),\n",
       " np.str_('ground,'),\n",
       " np.str_('hard,\"'),\n",
       " np.str_('said'),\n",
       " np.str_('Madam'),\n",
       " np.str_('Hooch.'),\n",
       " np.str_('\"Keep'),\n",
       " np.str_('your'),\n",
       " np.str_('brooms'),\n",
       " np.str_('steady,'),\n",
       " np.str_('rise'),\n",
       " np.str_('a'),\n",
       " np.str_('few'),\n",
       " np.str_('feet,'),\n",
       " np.str_('and'),\n",
       " np.str_('then'),\n",
       " np.str_('come'),\n",
       " np.str_('straight'),\n",
       " np.str_('back'),\n",
       " np.str_('down'),\n",
       " np.str_('by'),\n",
       " np.str_('leaning'),\n",
       " np.str_('forward'),\n",
       " np.str_('slightly.'),\n",
       " np.str_('On'),\n",
       " np.str_('my'),\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_input_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f648bb",
   "metadata": {},
   "source": [
    "## 2. compute LLM representations for these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0894014d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and tokenizer.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, cache_dir=HF_home)\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=HF_home).to(\"cuda\")\n",
    "print(\"Loaded model and tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c974265",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_to_find = LLM_input_sequence # we search for these words in sequential order in the full prompt to obtain avg representations for these.\n",
    "prompt_text = \" \".join(LLM_input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "124e23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met Draco Malfoy. Still, first-year Gryffindors only had Potions with the Slytherins, so they didn\\'t have to put up with Malfoy much. Or at least, they didn\\'t until they spotted a notice pinned up in the Gryffindor common room that made them all groan. Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be learning together. \\n\\n \"Typical,\" said Harry darkly. \"Just what I a',\n",
       " 28670)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text[:500], len(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f70674c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt_text.split(\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d8881d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met Draco Malfoy. Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put up with Malfoy much. Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that made them all groan. Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be learning together. \",\n",
       " ' \"Typical,\" said Harry darkly. \"Just what I always wanted. To make a fool of myself on a broomstick in front of Malfoy.\" ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text.split(\"\\n\\n\")[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030b04ae",
   "metadata": {},
   "source": [
    "### Restore order of word/representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd4d6a",
   "metadata": {},
   "source": [
    "### Compute representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6be7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed word level representations for the input sequence.\n"
     ]
    }
   ],
   "source": [
    "# compute representations \n",
    "occurrences, representations = get_ordered_representations(\n",
    "    ordered_strings_to_find=strings_to_find,\n",
    "    prompt=prompt_text,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")\n",
    "print(\"Computed word level representations for the input sequence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408eafa1",
   "metadata": {},
   "source": [
    "## 3. Map from word-level LLM representations to TR level representations via Lanczos resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c155988",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = -7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "361e607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing lanczos interpolation with cutoff=0.500 and 3 lobes.\n",
      "Interpolated LLM representations to match fMRI TRs via Lanczos downsampling.\n"
     ]
    }
   ],
   "source": [
    "interpolated_representations = lanczosinterp2D(\n",
    "    representations[layer_idx].to(\"cpu\"),             # shape: (n_samples_input, n_dim)\n",
    "    word_times,      # shape: (n_samples_input,)\n",
    "    fmri_time,     # shape: (n_samples_target,)\n",
    "    window=3,         # (optional) number of lobes for the window\n",
    "    cutoff_mult=1.0,  # (optional) cutoff frequency multiplier\n",
    "    rectify=False     # (optional) rectification\n",
    ")\n",
    "print(\"Interpolated LLM representations to match fMRI TRs via Lanczos downsampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "470c3e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351, 2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4b881",
   "metadata": {},
   "source": [
    "## 4. Concatenate last x TRs of the LLM representation\n",
    "No need to filter the first x features because we skip those anyway in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225ef5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_lag = 4  # number of previous TRs to concatenate\n",
    "interpolated_representations = concat_past_features(torch.from_numpy(interpolated_representations), N_lag).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df19dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351, 10240)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be8447",
   "metadata": {},
   "source": [
    "## 5. Filter out TRs at the boundary of multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a26b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted edges from the LLM representations to match the filtering of fMRI runs (removed first 20 and last 15 of every run).\n"
     ]
    }
   ],
   "source": [
    "# Delete the first 2 and last 1 elements from each experiment run\n",
    "n_begin = 20\n",
    "n_last = 15\n",
    "mask = fmri_runs # This is an integer mask indicating which TRs belong to which run.\n",
    "final_representations = delete_block_edges(interpolated_representations, \n",
    "                                           mask, \n",
    "                                           n_begin, \n",
    "                                           n_last, \n",
    "                                           axis=0) # axis 0: time-dimension is the first in our data\n",
    "print(f\"Deleted edges from the LLM representations to match the filtering of fMRI runs (removed first {n_begin} and last {n_last} of every run).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f091cbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 25263)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8899a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 10240)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84666e1f",
   "metadata": {},
   "source": [
    "## 6. Run the nested blocked cross-validation to find the best alpha per voxel for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b794f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch tensors and move to GPU\n",
    "X = torch.tensor(final_representations, dtype=torch.float32, device=\"cuda\") # shape (n_TRs, n_features)\n",
    "y = torch.tensor(fmri_data, dtype=torch.float32, device=\"cuda\") # shape (n_TRs, n_voxels)\n",
    "\n",
    "# Set parameters for crossvalidation\n",
    "split_function = \"blocked\" # divide data into uniform folds\n",
    "block_labels = None  # Not needed for blocked splitting - useful for experiment-wise CV folds\n",
    "n_splits_outer = 4   # Four blocks for outer CV (must be larger than 1)\n",
    "n_splits_inner = 3   # Three blocks for inner CV (must be larger than 1)\n",
    "gap = 15 # number of TRs to skip/discard in between train and test to avoid leakage\n",
    "alphas = [0.1,1,10,100,1000,10000] # default vals from https://github.com/mtoneva/brain_language_nlp/blob/master/utils/utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b0f8642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1211, 10240]), torch.Size([1211, 25263]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de37620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nested blocked cross-validation to find the best alpha per voxel for ridge regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   3%|█▋                                                     | 3/96 [00:20<10:48,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   6%|███▍                                                   | 6/96 [00:42<10:33,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   9%|█████▏                                                 | 9/96 [01:03<10:16,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  12%|██████▊                                               | 12/96 [01:25<09:59,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  16%|████████▍                                             | 15/96 [01:46<09:40,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  19%|██████████▏                                           | 18/96 [02:08<09:20,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(1, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=3.02053e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=2.99951e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "Ridge Regression models fitted:  20%|██████████▎                                         | 19/96 [05:41<1:28:36, 69.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [ 0.01598345  0.03589297  0.00654226 ... -0.01587435 -0.02176086\n",
      "  0.07683309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  23%|████████████▍                                         | 22/96 [06:02<34:48, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  26%|██████████████                                        | 25/96 [06:23<16:56, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  29%|███████████████▊                                      | 28/96 [06:45<10:51,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  32%|█████████████████▍                                    | 31/96 [07:06<08:39,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  35%|███████████████████▏                                  | 34/96 [07:32<08:46,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  39%|████████████████████▊                                 | 37/96 [07:57<08:11,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(2, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=3.19708e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=3.20749e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "Ridge Regression models fitted:  40%|█████████████████████▍                                | 38/96 [10:18<46:33, 48.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [ 0.04748398  0.10312871  0.0160238  ... -0.07810347 -0.11550666\n",
      " -0.06989722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  43%|███████████████████████                               | 41/96 [10:39<19:15, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  46%|████████████████████████▊                             | 44/96 [11:00<10:10, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  49%|██████████████████████████▍                           | 47/96 [11:20<07:01,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  52%|████████████████████████████▏                         | 50/96 [11:41<05:47,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  55%|█████████████████████████████▊                        | 53/96 [12:03<05:09,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  58%|███████████████████████████████▌                      | 56/96 [12:24<04:43,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(3, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=2.95486e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=2.95205e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "Ridge Regression models fitted:  59%|████████████████████████████████                      | 57/96 [14:47<31:09, 47.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [-0.06908432 -0.02936458 -0.08971171 ... -0.10627444 -0.12139738\n",
      " -0.02587006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  61%|█████████████████████████████████▏                    | 59/96 [15:07<09:29, 15.39s/it]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "print(\"Starting nested blocked cross-validation to find the best alpha per voxel for ridge regression\")\n",
    "# Obtain the best ridge regression penalties for each voxel independently (~25k alphas)\n",
    "best_alphas, outer_scores = nested_blocked_cv(\n",
    "    X, y,\n",
    "    split_function=split_function,\n",
    "    block_labels=block_labels,\n",
    "    n_splits_outer=n_splits_outer,\n",
    "    n_splits_inner=n_splits_inner,\n",
    "    gap=gap,\n",
    "    alphas=alphas,\n",
    "    device=device\n",
    ")\n",
    "print(\"Best alphas found:\", best_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_labels = [[0 for _ in range(X.shape[0])]] # everything comes from the same story so we assume identical block_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391a772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db78f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cajal",
   "language": "python",
   "name": "cajal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
