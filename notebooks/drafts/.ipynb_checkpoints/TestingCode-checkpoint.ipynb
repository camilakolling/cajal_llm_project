{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9974afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7ddbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/BRAIN/neuroai_project/work/Encoding_models'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_path = \"/BRAIN/neuroai_project/work/Encoding_models\"\n",
    "code_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc3cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed for pearson_correlation function.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(code_path)\n",
    "\n",
    "from encoding import *\n",
    "from preprocessing import get_ordered_representations, normalize_train_test, concat_past_features, lanczosinterp2D, delete_block_edges\n",
    "from encoding import nested_blocked_cv, ridge_regression_fit_sklearn, ridge_regression_predict_torch\n",
    "from analysis import pearson_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c369f",
   "metadata": {},
   "source": [
    "## 0. load fmri data and annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43058c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_prefix = \"/BRAIN/neuroai_project/work/Encoding_models/data/HP_data/fMRI\"\n",
    "HF_home = \"/SWS/llms/nobackup/\"\n",
    "results_path_prefix = \"/BRAIN/neuroai_project/work/Encoding_models/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e0b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1211, 25263),\n",
       " array([[-1.39391795e+00, -4.95610000e-01, -1.76625698e+00, ...,\n",
       "         -7.66158058e-01, -2.32445619e-01, -1.46871563e-01],\n",
       "        [ 5.30454149e-01, -2.32485978e-01,  3.52580458e-01, ...,\n",
       "         -2.31855518e-03, -2.46482123e-01, -4.29284279e-01],\n",
       "        [ 1.13308842e+00,  3.31803866e-01, -3.14589030e-01, ...,\n",
       "          8.15993870e-01,  1.31184511e+00,  1.38407545e+00],\n",
       "        ...,\n",
       "        [-1.10624234e+00, -1.08674185e+00, -5.44766153e-01, ...,\n",
       "          6.70158027e-01,  9.81612876e-01,  8.54572439e-01],\n",
       "        [-1.58241086e+00, -1.14630569e+00, -5.57836731e-01, ...,\n",
       "         -3.30246991e-01, -4.22094739e-01, -1.26951335e-01],\n",
       "        [-2.59743061e+00, -1.55403741e+00, -1.93496114e+00, ...,\n",
       "          1.01716606e+00,  2.10392591e-01,  1.11087041e-01]],\n",
       "       shape=(10, 25263)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw fmri data for one subject\n",
    "fmri_data = np.load(f\"{data_path_prefix}/data_subject_I.npy\", allow_pickle=True)\n",
    "fmri_data.shape, fmri_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3653a9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1351,), array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18], dtype=uint16))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing of each fmri TRs in seconds\n",
    "fmri_time = np.load(f\"{data_path_prefix}/time_fmri.npy\", allow_pickle=True)\n",
    "fmri_time.shape, fmri_time[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd0705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1351,), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint16))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of which TRs belong to which run.\n",
    "fmri_runs = np.load(f\"{data_path_prefix}/runs_fmri.npy\", allow_pickle=True)\n",
    "fmri_runs.shape, fmri_runs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a8f787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5176,),\n",
       " array(['Harry', 'had', 'never', 'believed', 'he', 'would', 'meet', 'a',\n",
       "        'boy', 'he'], dtype='<U14'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of words shown as stimuli (sequentially on a screen word by word)\n",
    "stimuli_words = np.load(f\"{data_path_prefix}/words_fmri.npy\", allow_pickle=True)\n",
    "stimuli_words.shape, stimuli_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b2efcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\" \".join(stimuli_words).split(\"+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8946f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5176,), array([20. , 20.5, 21. , 21.5, 22. , 22.5, 23. , 23.5, 24. , 24.5]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing in seconds of the words\n",
    "word_times = np.load(f\"{data_path_prefix}/time_words_fmri.npy\", allow_pickle=True)\n",
    "word_times.shape, word_times[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83b992",
   "metadata": {},
   "source": [
    "## 1. prepare the input sequence for the LLM\n",
    "(e.g. by changing formatting). Here we change \"+\" to \"\\n\\n\" and \"@\" to nothing (used to highlight italics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aeb6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_input_sequence = []\n",
    "for word in stimuli_words:\n",
    "    LLM_input_sequence.append(word) if word != \"+\" and not \"@\" in word \\\n",
    "    else LLM_input_sequence.append(word.replace(\"+\", \"\\n\\n\").replace(\"@\",\"\"))\n",
    "assert len(word_times.tolist()) == len(LLM_input_sequence), \"different length\" # make sure we still have the same length as we have word timings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f648bb",
   "metadata": {},
   "source": [
    "## 2. compute LLM representations for these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0894014d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and tokenizer.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, cache_dir=HF_home)\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=HF_home).to(\"cuda\")\n",
    "print(\"Loaded model and tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c974265",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_to_find = LLM_input_sequence # we search for these words in sequential order in the full prompt to obtain avg representations for these.\n",
    "prompt_text = \" \".join(LLM_input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "124e23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met Draco Malfoy. Still, first-year Gryffindors only had Potions with the Slytherins, so they didn\\'t have to put up with Malfoy much. Or at least, they didn\\'t until they spotted a notice pinned up in the Gryffindor common room that made them all groan. Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be learning together. \\n\\n \"Typical,\" said Harry darkly. \"Just what I a',\n",
       " 28670)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text[:500], len(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc04b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt_text.split(\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6be7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed word level representations for the input sequence.\n"
     ]
    }
   ],
   "source": [
    "# compute representations \n",
    "occurrences, representations = get_ordered_representations(\n",
    "    ordered_strings_to_find=strings_to_find,\n",
    "    prompt=prompt_text,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")\n",
    "print(\"Computed word level representations for the input sequence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408eafa1",
   "metadata": {},
   "source": [
    "## 3. Map from word-level LLM representations to TR level representations via Lanczos resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c155988",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = -7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "361e607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing lanczos interpolation with cutoff=0.500 and 3 lobes.\n",
      "Interpolated LLM representations to match fMRI TRs via Lanczos downsampling.\n"
     ]
    }
   ],
   "source": [
    "interpolated_representations = lanczosinterp2D(\n",
    "    representations[layer_idx].to(\"cpu\"),             # shape: (n_samples_input, n_dim)\n",
    "    word_times,      # shape: (n_samples_input,)\n",
    "    fmri_time,     # shape: (n_samples_target,)\n",
    "    window=3,         # (optional) number of lobes for the window\n",
    "    cutoff_mult=1.0,  # (optional) cutoff frequency multiplier\n",
    "    rectify=False     # (optional) rectification\n",
    ")\n",
    "print(\"Interpolated LLM representations to match fMRI TRs via Lanczos downsampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "470c3e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351, 2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4b881",
   "metadata": {},
   "source": [
    "## 4. Concatenate last x TRs of the LLM representation\n",
    "No need to filter the first x features because we skip those anyway in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225ef5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_lag = 4  # number of previous TRs to concatenate\n",
    "interpolated_representations = concat_past_features(torch.from_numpy(interpolated_representations), N_lag).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1df19dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351, 10240)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be8447",
   "metadata": {},
   "source": [
    "## 5. Filter out TRs at the boundary of multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a26b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted edges from the LLM representations to match the filtering of fMRI runs (removed first 20 and last 15 of every run).\n"
     ]
    }
   ],
   "source": [
    "# Delete the first 2 and last 1 elements from each experiment run\n",
    "n_begin = 20\n",
    "n_last = 15\n",
    "mask = fmri_runs # This is an integer mask indicating which TRs belong to which run.\n",
    "final_representations = delete_block_edges(interpolated_representations, \n",
    "                                           mask, \n",
    "                                           n_begin, \n",
    "                                           n_last, \n",
    "                                           axis=0) # axis 0: time-dimension is the first in our data\n",
    "print(f\"Deleted edges from the LLM representations to match the filtering of fMRI runs (removed first {n_begin} and last {n_last} of every run).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f091cbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 25263)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8899a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 10240)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84666e1f",
   "metadata": {},
   "source": [
    "## 6. Run the nested blocked cross-validation to find the best alpha per voxel for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b794f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch tensors and move to GPU\n",
    "X = torch.tensor(final_representations, dtype=torch.float32, device=\"cuda\") # shape (n_TRs, n_features)\n",
    "y = torch.tensor(fmri_data, dtype=torch.float32, device=\"cuda\") # shape (n_TRs, n_voxels)\n",
    "\n",
    "# Set parameters for crossvalidation\n",
    "split_function = \"blocked\" # divide data into uniform folds\n",
    "block_labels = None  # Not needed for blocked splitting - useful for experiment-wise CV folds\n",
    "n_splits_outer = 4   # Four blocks for outer CV (must be larger than 1)\n",
    "n_splits_inner = 3   # Three blocks for inner CV (must be larger than 1)\n",
    "gap = 15 # number of TRs to skip/discard in between train and test to avoid leakage\n",
    "alphas = [0.1,1,10,100,1000,10000] # default vals from https://github.com/mtoneva/brain_language_nlp/blob/master/utils/utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b0f8642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1211, 10240]), torch.Size([1211, 25263]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de37620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nested blocked cross-validation to find the best alpha per voxel for ridge regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   3%|█▋                                                     | 3/96 [00:20<10:48,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   6%|███▍                                                   | 6/96 [00:42<10:33,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   9%|█████▏                                                 | 9/96 [01:03<10:16,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  12%|██████▊                                               | 12/96 [01:25<09:59,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  16%|████████▍                                             | 15/96 [01:46<09:40,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  19%|██████████▏                                           | 18/96 [02:08<09:20,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(1, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=3.02053e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=2.99951e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "Ridge Regression models fitted:  20%|██████████▎                                         | 19/96 [05:41<1:28:36, 69.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [ 0.01598345  0.03589297  0.00654226 ... -0.01587435 -0.02176086\n",
      "  0.07683309]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  23%|████████████▍                                         | 22/96 [06:02<34:48, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  26%|██████████████                                        | 25/96 [06:23<16:56, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  29%|███████████████▊                                      | 28/96 [06:45<10:51,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  32%|█████████████████▍                                    | 31/96 [07:06<08:39,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  35%|███████████████████▏                                  | 34/96 [07:32<08:46,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  39%|████████████████████▊                                 | 37/96 [07:57<08:11,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(2, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=3.19708e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=3.20749e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "Ridge Regression models fitted:  40%|█████████████████████▍                                | 38/96 [10:18<46:33, 48.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [ 0.04748398  0.10312871  0.0160238  ... -0.07810347 -0.11550666\n",
      " -0.06989722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  43%|███████████████████████                               | 41/96 [10:39<19:15, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  46%|████████████████████████▊                             | 44/96 [11:00<10:10, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  49%|██████████████████████████▍                           | 47/96 [11:20<07:01,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  52%|████████████████████████████▏                         | 50/96 [11:41<05:47,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  55%|█████████████████████████████▊                        | 53/96 [12:03<05:09,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  58%|███████████████████████████████▌                      | 56/96 [12:24<04:43,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(3, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=2.95486e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/BRAIN/ckolling-phd/work/miniconda3/lib/python3.12/site-packages/scipy/_lib/_util.py:1226: LinAlgWarning: Ill-conditioned matrix (rcond=2.95205e-08): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "Ridge Regression models fitted:  59%|████████████████████████████████                      | 57/96 [14:47<31:09, 47.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [-0.06908432 -0.02936458 -0.08971171 ... -0.10627444 -0.12139738\n",
      " -0.02587006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  61%|█████████████████████████████████▏                    | 59/96 [15:07<09:29, 15.39s/it]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "print(\"Starting nested blocked cross-validation to find the best alpha per voxel for ridge regression\")\n",
    "# Obtain the best ridge regression penalties for each voxel independently (~25k alphas)\n",
    "best_alphas, outer_scores = nested_blocked_cv(\n",
    "    X, y,\n",
    "    split_function=split_function,\n",
    "    block_labels=block_labels,\n",
    "    n_splits_outer=n_splits_outer,\n",
    "    n_splits_inner=n_splits_inner,\n",
    "    gap=gap,\n",
    "    alphas=alphas,\n",
    "    device=device\n",
    ")\n",
    "print(\"Best alphas found:\", best_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_labels = [[0 for _ in range(X.shape[0])]] # everything comes from the same story so we assume identical block_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391a772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db78f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cajal",
   "language": "python",
   "name": "cajal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
