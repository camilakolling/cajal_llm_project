{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9974afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0c7ddbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_path = \"../\"\n",
    "code_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6cc3cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(code_path)\n",
    "\n",
    "from encoding import *\n",
    "from preprocessing import get_ordered_representations, normalize_train_test, concat_past_features, lanczosinterp2D, delete_block_edges, shuffle_words\n",
    "from encoding import nested_blocked_cv, ridge_regression_fit_sklearn, ridge_regression_predict_torch\n",
    "from analysis import pearson_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c369f",
   "metadata": {},
   "source": [
    "## 0. load fmri data and annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "43058c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_prefix = \"../data/HP_data/fMRI\"\n",
    "HF_home = \"/SWS/llms/nobackup/\"\n",
    "results_path_prefix = \"/BRAIN/neuroai_project/work/Encoding_models/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "71e0b582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1211, 25263),\n",
       " array([[-1.39391795e+00, -4.95610000e-01, -1.76625698e+00, ...,\n",
       "         -7.66158058e-01, -2.32445619e-01, -1.46871563e-01],\n",
       "        [ 5.30454149e-01, -2.32485978e-01,  3.52580458e-01, ...,\n",
       "         -2.31855518e-03, -2.46482123e-01, -4.29284279e-01],\n",
       "        [ 1.13308842e+00,  3.31803866e-01, -3.14589030e-01, ...,\n",
       "          8.15993870e-01,  1.31184511e+00,  1.38407545e+00],\n",
       "        ...,\n",
       "        [-1.10624234e+00, -1.08674185e+00, -5.44766153e-01, ...,\n",
       "          6.70158027e-01,  9.81612876e-01,  8.54572439e-01],\n",
       "        [-1.58241086e+00, -1.14630569e+00, -5.57836731e-01, ...,\n",
       "         -3.30246991e-01, -4.22094739e-01, -1.26951335e-01],\n",
       "        [-2.59743061e+00, -1.55403741e+00, -1.93496114e+00, ...,\n",
       "          1.01716606e+00,  2.10392591e-01,  1.11087041e-01]],\n",
       "       shape=(10, 25263)))"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw fmri data for one subject\n",
    "fmri_data = np.load(f\"{data_path_prefix}/data_subject_I.npy\", allow_pickle=True)\n",
    "fmri_data.shape, fmri_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "3653a9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1351,), array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18], dtype=uint16))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing of each fmri TRs in seconds\n",
    "fmri_time = np.load(f\"{data_path_prefix}/time_fmri.npy\", allow_pickle=True)\n",
    "fmri_time.shape, fmri_time[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1cd0705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1351,), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint16))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of which TRs belong to which run.\n",
    "fmri_runs = np.load(f\"{data_path_prefix}/runs_fmri.npy\", allow_pickle=True)\n",
    "fmri_runs.shape, fmri_runs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d5a8f787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5176,),\n",
       " array(['Harry', 'had', 'never', 'believed', 'he', 'would', 'meet', 'a',\n",
       "        'boy', 'he'], dtype='<U14'))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of words shown as stimuli (sequentially on a screen word by word)\n",
    "stimuli_words = np.load(f\"{data_path_prefix}/words_fmri.npy\", allow_pickle=True)\n",
    "stimuli_words.shape, stimuli_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8946f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5176,), array([20. , 20.5, 21. , 21.5, 22. , 22.5, 23. , 23.5, 24. , 24.5]))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timing in seconds of the words\n",
    "word_times = np.load(f\"{data_path_prefix}/time_words_fmri.npy\", allow_pickle=True)\n",
    "word_times.shape, word_times[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83b992",
   "metadata": {},
   "source": [
    "## 1. prepare the input sequence for the LLM\n",
    "(e.g. by changing formatting). Here we change \"+\" to \"\\n\\n\" and \"@\" to nothing (used to highlight italics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3aeb6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_input_sequence = []\n",
    "for word in stimuli_words:\n",
    "    LLM_input_sequence.append(word) if word != \"+\" and not \"@\" in word \\\n",
    "    else LLM_input_sequence.append(word.replace(\"+\", \"\\n\\n\").replace(\"@\",\"\"))\n",
    "assert len(word_times.tolist()) == len(LLM_input_sequence), \"different length\" # make sure we still have the same length as we have word timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7f4ab090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "def shuffle_words(words: List[str], percentage: float, seed: int = 42, exclude_tokens: List[str] = [\"\\n\\n\"]) -> Tuple[List[str], List[int]]:\n",
    "\n",
    "    assert 0 <= percentage <= 1, \"percentage must be between 0 and 1\"\n",
    "\n",
    "    # Identify positions of words to consider for shuffling\n",
    "    shuffle_indices = [i for i, w in enumerate(words) if w not in exclude_tokens]\n",
    "    num_to_shuffle = int(len(shuffle_indices) * percentage)\n",
    "\n",
    "    if num_to_shuffle == 0:\n",
    "        return words.copy(), list(range(len(words)))\n",
    "\n",
    "    # Randomly sample indices to shuffle\n",
    "    random.seed(seed)\n",
    "    indices_to_shuffle = random.sample(shuffle_indices, num_to_shuffle)\n",
    "\n",
    "    # Extract and shuffle the selected words\n",
    "    words_to_shuffle = [words[i] for i in indices_to_shuffle]\n",
    "    random.shuffle(words_to_shuffle)\n",
    "\n",
    "    # Insert shuffled words back\n",
    "    shuffled_words = words.copy()\n",
    "    for idx, new_word in zip(indices_to_shuffle, words_to_shuffle):\n",
    "        shuffled_words[idx] = new_word\n",
    "\n",
    "    # Build inverse mapping (from new positions back to original indices)\n",
    "    inverse_indices = list(range(len(words)))\n",
    "    for i, new_word in zip(indices_to_shuffle, words_to_shuffle):\n",
    "        original_index = words.index(new_word)  # Caution: If duplicates exist, this gives first match\n",
    "        inverse_indices[i] = original_index\n",
    "\n",
    "    return shuffled_words, inverse_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "43e8851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_sequence, inverse = shuffle_words(LLM_input_sequence, percentage=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2d9c4242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5176"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a494a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "seed_value=42\n",
    "# Track the positions of special tokens to exclude from shuffling\n",
    "shuffle_indices = [i for i, w in enumerate(LLM_input_sequence) if w not in [\"\\n\\n\"]]\n",
    "# Extract and shuffle the words to be shuffled\n",
    "words_to_shuffle = [LLM_input_sequence[i] for i in shuffle_indices]\n",
    "shuffled_words = words_to_shuffle.copy()\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.shuffle(shuffled_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "73d64c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4975"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shuffle_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "27fda54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the full sequence with shuffled words and preserved special tokens\n",
    "final_sequence = LLM_input_sequence.copy()\n",
    "for idx, word_idx in enumerate(shuffle_indices):\n",
    "    final_sequence[word_idx] = shuffled_words[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "36057a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5176"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LLM_input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fea6c52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5176"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2a819fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inverse_indices(original: List[str], shuffled: List[str]) -> List[int]:\n",
    "    from collections import defaultdict\n",
    "    used = defaultdict(int)\n",
    "    index_map = defaultdict(list)\n",
    "    \n",
    "    # Map all occurrences of each word to their positions in the original\n",
    "    for i, word in enumerate(original):\n",
    "        index_map[word].append(i)\n",
    "\n",
    "    indices = []\n",
    "    for word in shuffled:\n",
    "        idx = index_map[word][used[word]]\n",
    "        indices.append(idx)\n",
    "        used[word] += 1\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2dae0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_indices = compute_inverse_indices(original=final_sequence, shuffled=LLM_input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "501df1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[252,\n",
       " 1538,\n",
       " 1507,\n",
       " 3,\n",
       " 5021,\n",
       " 23,\n",
       " 3142,\n",
       " 218,\n",
       " 394,\n",
       " 3431,\n",
       " 934,\n",
       " 3815,\n",
       " 39,\n",
       " 25,\n",
       " 666,\n",
       " 47,\n",
       " 1495,\n",
       " 1192,\n",
       " 44,\n",
       " 129,\n",
       " 894,\n",
       " 357,\n",
       " 119,\n",
       " 1344,\n",
       " 1412,\n",
       " 3614,\n",
       " 130,\n",
       " 349,\n",
       " 62,\n",
       " 478,\n",
       " 82,\n",
       " 503,\n",
       " 246,\n",
       " 1894,\n",
       " 131,\n",
       " 768,\n",
       " 549,\n",
       " 71,\n",
       " 242,\n",
       " 64,\n",
       " 31,\n",
       " 32,\n",
       " 2,\n",
       " 158,\n",
       " 76,\n",
       " 147,\n",
       " 495,\n",
       " 33,\n",
       " 60,\n",
       " 146,\n",
       " 70,\n",
       " 645,\n",
       " 435,\n",
       " 2054,\n",
       " 1434,\n",
       " 281,\n",
       " 45,\n",
       " 104,\n",
       " 4976,\n",
       " 153,\n",
       " 3801,\n",
       " 517,\n",
       " 1237,\n",
       " 1699,\n",
       " 1743,\n",
       " 575,\n",
       " 900,\n",
       " 1150,\n",
       " 2692,\n",
       " 150,\n",
       " 237,\n",
       " 113,\n",
       " 1294,\n",
       " 497,\n",
       " 21,\n",
       " 1621,\n",
       " 54,\n",
       " 34,\n",
       " 368,\n",
       " 79,\n",
       " 1827,\n",
       " 771,\n",
       " 874,\n",
       " 1173,\n",
       " 756,\n",
       " 363,\n",
       " 109,\n",
       " 477,\n",
       " 208,\n",
       " 228,\n",
       " 84,\n",
       " 1910,\n",
       " 72,\n",
       " 618,\n",
       " 125,\n",
       " 5046,\n",
       " 194,\n",
       " 154,\n",
       " 447,\n",
       " 852,\n",
       " 542,\n",
       " 4424,\n",
       " 102,\n",
       " 343,\n",
       " 2883,\n",
       " 245,\n",
       " 583,\n",
       " 839,\n",
       " 36,\n",
       " 576,\n",
       " 718,\n",
       " 3208,\n",
       " 607,\n",
       " 108,\n",
       " 231,\n",
       " 1318,\n",
       " 780,\n",
       " 4433,\n",
       " 1720,\n",
       " 210,\n",
       " 4121,\n",
       " 327,\n",
       " 1689,\n",
       " 2132,\n",
       " 192,\n",
       " 1392,\n",
       " 457,\n",
       " 2295,\n",
       " 183,\n",
       " 3762,\n",
       " 562,\n",
       " 138,\n",
       " 264,\n",
       " 2373,\n",
       " 2996,\n",
       " 1041,\n",
       " 1929,\n",
       " 1362,\n",
       " 3997,\n",
       " 2366,\n",
       " 1637,\n",
       " 1005,\n",
       " 55,\n",
       " 1451,\n",
       " 170,\n",
       " 85,\n",
       " 52,\n",
       " 136,\n",
       " 211,\n",
       " 149,\n",
       " 1321,\n",
       " 2304,\n",
       " 268,\n",
       " 761,\n",
       " 10,\n",
       " 399,\n",
       " 2551,\n",
       " 92,\n",
       " 49,\n",
       " 3166,\n",
       " 480,\n",
       " 4562,\n",
       " 176,\n",
       " 2074,\n",
       " 4001,\n",
       " 663,\n",
       " 87,\n",
       " 2185,\n",
       " 74,\n",
       " 552,\n",
       " 620,\n",
       " 184,\n",
       " 112,\n",
       " 917,\n",
       " 396,\n",
       " 446,\n",
       " 508,\n",
       " 2170,\n",
       " 1870,\n",
       " 1156,\n",
       " 77,\n",
       " 2047,\n",
       " 325,\n",
       " 739,\n",
       " 699,\n",
       " 1483,\n",
       " 93,\n",
       " 1054,\n",
       " 1876,\n",
       " 3549,\n",
       " 2260,\n",
       " 4120,\n",
       " 421,\n",
       " 2165,\n",
       " 1528,\n",
       " 2336,\n",
       " 9,\n",
       " 1087,\n",
       " 271,\n",
       " 243,\n",
       " 755,\n",
       " 2229,\n",
       " 2768,\n",
       " 770,\n",
       " 409,\n",
       " 161,\n",
       " 590,\n",
       " 933,\n",
       " 416,\n",
       " 555,\n",
       " 120,\n",
       " 1795,\n",
       " 190,\n",
       " 1515,\n",
       " 800,\n",
       " 41,\n",
       " 103,\n",
       " 18,\n",
       " 3585,\n",
       " 1899,\n",
       " 115,\n",
       " 2200,\n",
       " 449,\n",
       " 97,\n",
       " 118,\n",
       " 128,\n",
       " 749,\n",
       " 1051,\n",
       " 259,\n",
       " 48,\n",
       " 2442,\n",
       " 462,\n",
       " 135,\n",
       " 275,\n",
       " 623,\n",
       " 785,\n",
       " 98,\n",
       " 165,\n",
       " 126,\n",
       " 37,\n",
       " 162,\n",
       " 152,\n",
       " 279,\n",
       " 1642,\n",
       " 1506,\n",
       " 1625,\n",
       " 950,\n",
       " 5162,\n",
       " 1539,\n",
       " 148,\n",
       " 163,\n",
       " 3854,\n",
       " 3761,\n",
       " 1132,\n",
       " 187,\n",
       " 2460,\n",
       " 1691,\n",
       " 899,\n",
       " 2650,\n",
       " 80,\n",
       " 1255,\n",
       " 342,\n",
       " 1610,\n",
       " 1048,\n",
       " 2422,\n",
       " 593,\n",
       " 107,\n",
       " 744,\n",
       " 2945,\n",
       " 527,\n",
       " 960,\n",
       " 197,\n",
       " 296,\n",
       " 1317,\n",
       " 591,\n",
       " 189,\n",
       " 204,\n",
       " 3249,\n",
       " 1826,\n",
       " 88,\n",
       " 3130,\n",
       " 2224,\n",
       " 1230,\n",
       " 175,\n",
       " 3482,\n",
       " 2419,\n",
       " 573,\n",
       " 509,\n",
       " 214,\n",
       " 1452,\n",
       " 670,\n",
       " 856,\n",
       " 976,\n",
       " 1866,\n",
       " 1598,\n",
       " 295,\n",
       " 344,\n",
       " 65,\n",
       " 258,\n",
       " 1138,\n",
       " 354,\n",
       " 202,\n",
       " 139,\n",
       " 2426,\n",
       " 116,\n",
       " 2896,\n",
       " 1038,\n",
       " 3412,\n",
       " 2230,\n",
       " 578,\n",
       " 4172,\n",
       " 3019,\n",
       " 3960,\n",
       " 599,\n",
       " 1460,\n",
       " 1705,\n",
       " 3470,\n",
       " 3228,\n",
       " 3212,\n",
       " 2153,\n",
       " 923,\n",
       " 4767,\n",
       " 414,\n",
       " 251,\n",
       " 172,\n",
       " 277,\n",
       " 427,\n",
       " 114,\n",
       " 1755,\n",
       " 4875,\n",
       " 998,\n",
       " 380,\n",
       " 180,\n",
       " 94,\n",
       " 600,\n",
       " 355,\n",
       " 2853,\n",
       " 341,\n",
       " 822,\n",
       " 339,\n",
       " 928,\n",
       " 4341,\n",
       " 203,\n",
       " 3053,\n",
       " 1067,\n",
       " 308,\n",
       " 303,\n",
       " 554,\n",
       " 430,\n",
       " 2032,\n",
       " 169,\n",
       " 470,\n",
       " 3586,\n",
       " 648,\n",
       " 630,\n",
       " 270,\n",
       " 181,\n",
       " 504,\n",
       " 1750,\n",
       " 1732,\n",
       " 5131,\n",
       " 466,\n",
       " 311,\n",
       " 802,\n",
       " 374,\n",
       " 2799,\n",
       " 4815,\n",
       " 289,\n",
       " 451,\n",
       " 1002,\n",
       " 595,\n",
       " 2564,\n",
       " 235,\n",
       " 1007,\n",
       " 876,\n",
       " 4134,\n",
       " 1415,\n",
       " 4430,\n",
       " 22,\n",
       " 1219,\n",
       " 5119,\n",
       " 263,\n",
       " 1016,\n",
       " 4677,\n",
       " 487,\n",
       " 205,\n",
       " 929,\n",
       " 982,\n",
       " 2096,\n",
       " 494,\n",
       " 514,\n",
       " 1427,\n",
       " 565,\n",
       " 419,\n",
       " 1976,\n",
       " 1488,\n",
       " 42,\n",
       " 710,\n",
       " 459,\n",
       " 300,\n",
       " 222,\n",
       " 304,\n",
       " 582,\n",
       " 219,\n",
       " 373,\n",
       " 2140,\n",
       " 167,\n",
       " 849,\n",
       " 479,\n",
       " 1812,\n",
       " 639,\n",
       " 732,\n",
       " 1509,\n",
       " 2876,\n",
       " 1977,\n",
       " 463,\n",
       " 393,\n",
       " 701,\n",
       " 423,\n",
       " 250,\n",
       " 241,\n",
       " 4819,\n",
       " 404,\n",
       " 312,\n",
       " 864,\n",
       " 441,\n",
       " 896,\n",
       " 4293,\n",
       " 185,\n",
       " 1685,\n",
       " 1182,\n",
       " 431,\n",
       " 4561,\n",
       " 96,\n",
       " 1072,\n",
       " 1966,\n",
       " 530,\n",
       " 156,\n",
       " 1265,\n",
       " 307,\n",
       " 2808,\n",
       " 468,\n",
       " 4056,\n",
       " 2147,\n",
       " 2202,\n",
       " 556,\n",
       " 1320,\n",
       " 1394,\n",
       " 598,\n",
       " 4946,\n",
       " 4298,\n",
       " 981,\n",
       " 403,\n",
       " 2591,\n",
       " 558,\n",
       " 367,\n",
       " 299,\n",
       " 687,\n",
       " 1155,\n",
       " 678,\n",
       " 455,\n",
       " 3167,\n",
       " 315,\n",
       " 232,\n",
       " 199,\n",
       " 2111,\n",
       " 1692,\n",
       " 2533,\n",
       " 635,\n",
       " 1500,\n",
       " 519,\n",
       " 471,\n",
       " 249,\n",
       " 722,\n",
       " 2378,\n",
       " 2403,\n",
       " 248,\n",
       " 326,\n",
       " 376,\n",
       " 213,\n",
       " 122,\n",
       " 548,\n",
       " 880,\n",
       " 753,\n",
       " 550,\n",
       " 1198,\n",
       " 2603,\n",
       " 651,\n",
       " 523,\n",
       " 4974,\n",
       " 520,\n",
       " 640,\n",
       " 2399,\n",
       " 655,\n",
       " 266,\n",
       " 1214,\n",
       " 1787,\n",
       " 1422,\n",
       " 1551,\n",
       " 99,\n",
       " 4392,\n",
       " 878,\n",
       " 566,\n",
       " 569,\n",
       " 2933,\n",
       " 3791,\n",
       " 579,\n",
       " 507,\n",
       " 3850,\n",
       " 272,\n",
       " 2958,\n",
       " 622,\n",
       " 693,\n",
       " 1353,\n",
       " 365,\n",
       " 757,\n",
       " 638,\n",
       " 1341,\n",
       " 4613,\n",
       " 1607,\n",
       " 2331,\n",
       " 1382,\n",
       " 262,\n",
       " 3179,\n",
       " 411,\n",
       " 4195,\n",
       " 660,\n",
       " 2498,\n",
       " 597,\n",
       " 2392,\n",
       " 1311,\n",
       " 3209,\n",
       " 345,\n",
       " 2899,\n",
       " 4619,\n",
       " 525,\n",
       " 1074,\n",
       " 1768,\n",
       " 253,\n",
       " 127,\n",
       " 3811,\n",
       " 586,\n",
       " 611,\n",
       " 3162,\n",
       " 200,\n",
       " 324,\n",
       " 953,\n",
       " 2259,\n",
       " 323,\n",
       " 201,\n",
       " 4176,\n",
       " 649,\n",
       " 347,\n",
       " 892,\n",
       " 437,\n",
       " 2480,\n",
       " 2757,\n",
       " 2539,\n",
       " 356,\n",
       " 559,\n",
       " 182,\n",
       " 1183,\n",
       " 1089,\n",
       " 2410,\n",
       " 1909,\n",
       " 2462,\n",
       " 464,\n",
       " 159,\n",
       " 912,\n",
       " 3611,\n",
       " 316,\n",
       " 4558,\n",
       " 4847,\n",
       " 4523,\n",
       " 650,\n",
       " 3337,\n",
       " 1612,\n",
       " 450,\n",
       " 679,\n",
       " 1802,\n",
       " 691,\n",
       " 2267,\n",
       " 4703,\n",
       " 38,\n",
       " 584,\n",
       " 134,\n",
       " 381,\n",
       " 3488,\n",
       " 444,\n",
       " 3332,\n",
       " 402,\n",
       " 456,\n",
       " 95,\n",
       " 2961,\n",
       " 5103,\n",
       " 848,\n",
       " 938,\n",
       " 965,\n",
       " 1865,\n",
       " 29,\n",
       " 783,\n",
       " 681,\n",
       " 2241,\n",
       " 1012,\n",
       " 1859,\n",
       " 66,\n",
       " 290,\n",
       " 16,\n",
       " 240,\n",
       " 484,\n",
       " 692,\n",
       " 198,\n",
       " 721,\n",
       " 469,\n",
       " 3818,\n",
       " 2063,\n",
       " 335,\n",
       " 1711,\n",
       " 297,\n",
       " 3113,\n",
       " 2711,\n",
       " 621,\n",
       " 1849,\n",
       " 3174,\n",
       " 2453,\n",
       " 625,\n",
       " 4382,\n",
       " 3993,\n",
       " 927,\n",
       " 4928,\n",
       " 433,\n",
       " 631,\n",
       " 674,\n",
       " 706,\n",
       " 872,\n",
       " 3775,\n",
       " 4199,\n",
       " 2252,\n",
       " 1165,\n",
       " 3448,\n",
       " 2478,\n",
       " 2994,\n",
       " 642,\n",
       " 2126,\n",
       " 267,\n",
       " 3273,\n",
       " 2271,\n",
       " 1004,\n",
       " 4634,\n",
       " 3467,\n",
       " 736,\n",
       " 1104,\n",
       " 426,\n",
       " 492,\n",
       " 837,\n",
       " 1778,\n",
       " 747,\n",
       " 657,\n",
       " 658,\n",
       " 962,\n",
       " 716,\n",
       " 1047,\n",
       " 879,\n",
       " 1042,\n",
       " 2144,\n",
       " 276,\n",
       " 3181,\n",
       " 1201,\n",
       " 2785,\n",
       " 5116,\n",
       " 2790,\n",
       " 3012,\n",
       " 4884,\n",
       " 816,\n",
       " 3438,\n",
       " 1603,\n",
       " 501,\n",
       " 518,\n",
       " 2565,\n",
       " 777,\n",
       " 392,\n",
       " 2992,\n",
       " 905,\n",
       " 1987,\n",
       " 510,\n",
       " 528,\n",
       " 4564,\n",
       " 4874,\n",
       " 604,\n",
       " 3032,\n",
       " 2886,\n",
       " 881,\n",
       " 857,\n",
       " 561,\n",
       " 891,\n",
       " 443,\n",
       " 536,\n",
       " 4125,\n",
       " 3973,\n",
       " 612,\n",
       " 790,\n",
       " 2016,\n",
       " 1330,\n",
       " 4582,\n",
       " 1177,\n",
       " 2239,\n",
       " 371,\n",
       " 835,\n",
       " 609,\n",
       " 2237,\n",
       " 4688,\n",
       " 123,\n",
       " 1122,\n",
       " 4404,\n",
       " 2672,\n",
       " 617,\n",
       " 337,\n",
       " 774,\n",
       " 821,\n",
       " 2998,\n",
       " 1093,\n",
       " 581,\n",
       " 3035,\n",
       " 2954,\n",
       " 567,\n",
       " 1978,\n",
       " 726,\n",
       " 361,\n",
       " 168,\n",
       " 5166,\n",
       " 3793,\n",
       " 1170,\n",
       " 3486,\n",
       " 574,\n",
       " 1176,\n",
       " 1404,\n",
       " 1880,\n",
       " 227,\n",
       " 834,\n",
       " 725,\n",
       " 553,\n",
       " 2086,\n",
       " 3443,\n",
       " 915,\n",
       " 1020,\n",
       " 1167,\n",
       " 723,\n",
       " 475,\n",
       " 2397,\n",
       " 1079,\n",
       " 1567,\n",
       " 2203,\n",
       " 221,\n",
       " 1833,\n",
       " 286,\n",
       " 1092,\n",
       " 369,\n",
       " 2526,\n",
       " 652,\n",
       " 417,\n",
       " 3613,\n",
       " 537,\n",
       " 643,\n",
       " 3094,\n",
       " 636,\n",
       " 57,\n",
       " 1268,\n",
       " 734,\n",
       " 1482,\n",
       " 667,\n",
       " 742,\n",
       " 1256,\n",
       " 1580,\n",
       " 705,\n",
       " 1141,\n",
       " 223,\n",
       " 776,\n",
       " 956,\n",
       " 454,\n",
       " 992,\n",
       " 1962,\n",
       " 750,\n",
       " 3013,\n",
       " 4684,\n",
       " 224,\n",
       " 1096,\n",
       " 1591,\n",
       " 1236,\n",
       " 2296,\n",
       " 425,\n",
       " 811,\n",
       " 294,\n",
       " 424,\n",
       " 793,\n",
       " 428,\n",
       " 760,\n",
       " 737,\n",
       " 4018,\n",
       " 788,\n",
       " 1028,\n",
       " 1324,\n",
       " 1073,\n",
       " 1476,\n",
       " 1484,\n",
       " 1740,\n",
       " 1152,\n",
       " 694,\n",
       " 2078,\n",
       " 389,\n",
       " 410,\n",
       " 2523,\n",
       " 5135,\n",
       " 812,\n",
       " 448,\n",
       " 4952,\n",
       " 1728,\n",
       " 698,\n",
       " 724,\n",
       " 513,\n",
       " 614,\n",
       " 1366,\n",
       " 633,\n",
       " 580,\n",
       " 2251,\n",
       " 616,\n",
       " 988,\n",
       " 4945,\n",
       " 2858,\n",
       " 1517,\n",
       " 544,\n",
       " 2026,\n",
       " 1550,\n",
       " 832,\n",
       " 4391,\n",
       " 283,\n",
       " 1564,\n",
       " 941,\n",
       " 1211,\n",
       " 3233,\n",
       " 1204,\n",
       " 773,\n",
       " 1936,\n",
       " 1274,\n",
       " 711,\n",
       " 1521,\n",
       " 63,\n",
       " 233,\n",
       " 702,\n",
       " 5114,\n",
       " 515,\n",
       " 850,\n",
       " 1823,\n",
       " 1885,\n",
       " 1069,\n",
       " 854,\n",
       " 1304,\n",
       " 58,\n",
       " 360,\n",
       " 2821,\n",
       " 390,\n",
       " 1537,\n",
       " 1025,\n",
       " 3093,\n",
       " 1944,\n",
       " 2447,\n",
       " 594,\n",
       " 1281,\n",
       " 2369,\n",
       " 86,\n",
       " 522,\n",
       " 2391,\n",
       " 1566,\n",
       " 2647,\n",
       " 828,\n",
       " 1871,\n",
       " 752,\n",
       " 1445,\n",
       " 637,\n",
       " 1158,\n",
       " 491,\n",
       " 949,\n",
       " 1292,\n",
       " 422,\n",
       " 420,\n",
       " 870,\n",
       " 4214,\n",
       " 256,\n",
       " 274,\n",
       " 570,\n",
       " 2030,\n",
       " 2289,\n",
       " 3844,\n",
       " 1136,\n",
       " 209,\n",
       " 3450,\n",
       " 1776,\n",
       " 4124,\n",
       " 1030,\n",
       " 526,\n",
       " 4831,\n",
       " 808,\n",
       " 967,\n",
       " 866,\n",
       " 3716,\n",
       " 765,\n",
       " 914,\n",
       " 1043,\n",
       " 825,\n",
       " 322,\n",
       " 516,\n",
       " 1127,\n",
       " 2435,\n",
       " 75,\n",
       " 439,\n",
       " 919,\n",
       " 2427,\n",
       " 603,\n",
       " 686,\n",
       " 1355,\n",
       " 709,\n",
       " 1406,\n",
       " 921,\n",
       " 1970,\n",
       " 1652,\n",
       " 1133,\n",
       " 2018,\n",
       " 577,\n",
       " 809,\n",
       " 2482,\n",
       " 2344,\n",
       " 1497,\n",
       " 1229,\n",
       " 1263,\n",
       " 1314,\n",
       " 1431,\n",
       " 1793,\n",
       " 332,\n",
       " 5041,\n",
       " 2290,\n",
       " 841,\n",
       " 5016,\n",
       " 4185,\n",
       " 3653,\n",
       " 810,\n",
       " 1811,\n",
       " 2625,\n",
       " 196,\n",
       " 3227,\n",
       " 3957,\n",
       " 2188,\n",
       " 3641,\n",
       " 220,\n",
       " 2039,\n",
       " 4277,\n",
       " 707,\n",
       " 2010,\n",
       " 1393,\n",
       " 733,\n",
       " 2775,\n",
       " 661,\n",
       " 813,\n",
       " 4548,\n",
       " 1190,\n",
       " 963,\n",
       " 1045,\n",
       " 1199,\n",
       " 972,\n",
       " 4024,\n",
       " 453,\n",
       " 1026,\n",
       " 2449,\n",
       " 3004,\n",
       " 713,\n",
       " 1673,\n",
       " 4303,\n",
       " 2110,\n",
       " 3403,\n",
       " 1272,\n",
       " 925,\n",
       " 284,\n",
       " 226,\n",
       " 4219,\n",
       " 1733,\n",
       " 2261,\n",
       " 767,\n",
       " 766,\n",
       " 646,\n",
       " 1009,\n",
       " 3270,\n",
       " 2505,\n",
       " 3202,\n",
       " 1581,\n",
       " 2587,\n",
       " 641,\n",
       " 2930,\n",
       " 845,\n",
       " 4055,\n",
       " 244,\n",
       " 3165,\n",
       " 1270,\n",
       " ...]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "97538d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_indices_old = [None] * len(words_to_shuffle)\n",
    "# used = [False] * len(words_to_shuffle)\n",
    "\n",
    "# for i, word in enumerate(shuffled_words):\n",
    "#     for j, (orig_word, flag) in enumerate(zip(words_to_shuffle, used)):\n",
    "#         if not flag and word == orig_word:\n",
    "#             inverse_indices[i] = shuffle_indices[j]\n",
    "#             used[j] = True\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "84b50753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(inverse_indices_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "17fa47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose one of the following (set only one to True)\n",
    "# shuffle_paragraphs_flag = True\n",
    "# shuffle_sentences_flag = False\n",
    "# shuffle_words_flag = True\n",
    "\n",
    "# if shuffle_words_flag:\n",
    "#     LLM_input_sequence, inverse_indices = shuffle_words(LLM_input_sequence)\n",
    "# else:\n",
    "#     inverse_indices = list(range(len(LLM_input_sequence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f648bb",
   "metadata": {},
   "source": [
    "## 2. compute LLM representations for these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ee051339",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_input_sequence=shuffled_sequence.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bbd6b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to a writable location, like /tmp or your home dir\n",
    "HF_home = \"/tmp/huggingface_cache\"  # or \"/home/youruser/.cache/huggingface\"\n",
    "\n",
    "os.makedirs(HF_home, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0894014d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and tokenizer.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, cache_dir=HF_home)\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=HF_home).to(\"cpu\")\n",
    "print(\"Loaded model and tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4c974265",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_to_find = LLM_input_sequence # we search for these words in sequential order in the full prompt to obtain avg representations for these.\n",
    "prompt_text = \" \".join(LLM_input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "124e23ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Harry had never school few would meet a boy of her. whispered, than constantly. but that was flying he met Draco and Still, first-year Gryffindors only now Potions with more Slytherins, so they which have to put up thing Malfoy much. Or at least, they Malfoy, until they if a notice pinned up gray the Gryffindor common Patil felt made there all \"RUN!\" Flying toward would be starting on Thursday -- and Gryffindor and Slytherin would broom. learning together. \\n\\n obviously said Harry darkly. any what I always Wood To Quidditch a fool of myself shouted, a broomstick in front of could \\n\\n He knows, \"Half-past looking wasn\\'t to POTTER!\" to fly more than \"But else. \"You just know that in make grandmother. fool of yourself,\" said Ron reasonably. McGonagall, I know Malfoy\\'s always going on wiping how and he is at Quidditch, pushed I bet that\\'s all talk.\" \\n\\n feet. certainly did talk lump?\" fist. a lot. He complained loudly course we snatched in getting on the House from teams and hear long, boastf',\n",
       " 28670)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text[:1000], len(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b6be7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed word level representations for the input sequence.\n"
     ]
    }
   ],
   "source": [
    "# compute representations \n",
    "occurrences, representations = get_ordered_representations(\n",
    "    ordered_strings_to_find=strings_to_find,\n",
    "    prompt=prompt_text,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")\n",
    "print(\"Computed word level representations for the input sequence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4c9f93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5176, 2048])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representations[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408eafa1",
   "metadata": {},
   "source": [
    "## 3. Map from word-level LLM representations to TR level representations via Lanczos resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2c155988",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = -7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4310b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step: Reorder the model output (shuffled order) back to original order using inverse_indices\n",
    "reordered_representations = representations[layer_idx][inverse_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "97a25f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# word_times must be ordered the same as reordered_representations\n",
    "reordered_word_times = word_times[inverse_indices]  # Make sure this works after fixing inverse_indices\n",
    "\n",
    "# Ensure representation and word_times match\n",
    "assert reordered_representations.shape[0] == reordered_word_times.shape[0], \"Mismatch in # of tokens and timings\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "53a0f7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0677, -0.0360,  0.0615,  ..., -0.0089, -0.0587,  0.1323],\n",
       "        [-0.0310,  0.0188,  0.1457,  ...,  0.0583, -0.0184,  0.0235],\n",
       "        [-0.1548, -0.0597, -0.1306,  ...,  0.0993, -0.0981, -0.1199],\n",
       "        ...,\n",
       "        [-0.0158, -0.0544, -0.0908,  ...,  0.0270,  0.2075,  0.1604],\n",
       "        [ 0.0695, -0.0129,  0.0099,  ...,  0.0773,  0.0125, -0.0410],\n",
       "        [ 0.0142, -0.1359, -0.0463,  ..., -0.0331, -0.1123, -0.1860]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reordered_representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8490b870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reordered_representations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "361e607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing lanczos interpolation with cutoff=0.500 and 3 lobes.\n",
      "Interpolated LLM representations to match fMRI TRs via Lanczos downsampling.\n"
     ]
    }
   ],
   "source": [
    "interpolated_representations = lanczosinterp2D(\n",
    "    reordered_representations.to(\"cpu\"),             # shape: (n_samples_input, n_dim)\n",
    "    word_times,      # shape: (n_samples_input,)\n",
    "    fmri_time,     # shape: (n_samples_target,)\n",
    "    window=3,         # (optional) number of lobes for the window\n",
    "    cutoff_mult=1.0,  # (optional) cutoff frequency multiplier\n",
    "    rectify=False     # (optional) rectification\n",
    ")\n",
    "print(\"Interpolated LLM representations to match fMRI TRs via Lanczos downsampling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "470c3e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351, 2048)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4b881",
   "metadata": {},
   "source": [
    "## 4. Concatenate last x TRs of the LLM representation\n",
    "No need to filter the first x features because we skip those anyway in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "225ef5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_lag = 4  # number of previous TRs to concatenate\n",
    "interpolated_representations = concat_past_features(torch.from_numpy(interpolated_representations), N_lag).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1df19dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351, 10240)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be8447",
   "metadata": {},
   "source": [
    "## 5. Filter out TRs at the boundary of multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6a26b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted edges from the LLM representations to match the filtering of fMRI runs (removed first 20 and last 15 of every run).\n"
     ]
    }
   ],
   "source": [
    "# Delete the first 2 and last 1 elements from each experiment run\n",
    "n_begin = 20\n",
    "n_last = 15\n",
    "mask = fmri_runs # This is an integer mask indicating which TRs belong to which run.\n",
    "final_representations = delete_block_edges(interpolated_representations, \n",
    "                                           mask, \n",
    "                                           n_begin, \n",
    "                                           n_last, \n",
    "                                           axis=0) # axis 0: time-dimension is the first in our data\n",
    "print(f\"Deleted edges from the LLM representations to match the filtering of fMRI runs (removed first {n_begin} and last {n_last} of every run).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f091cbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 25263)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8899a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 10240)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84666e1f",
   "metadata": {},
   "source": [
    "## 6. Run the nested blocked cross-validation to find the best alpha per voxel for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8b794f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch tensors and move to GPU\n",
    "X = torch.tensor(final_representations, dtype=torch.float32, device=\"cpu\") # shape (n_TRs, n_features)\n",
    "y = torch.tensor(fmri_data, dtype=torch.float32, device=\"cpu\") # shape (n_TRs, n_voxels)\n",
    "\n",
    "# Set parameters for crossvalidation\n",
    "split_function = \"blocked\" # divide data into uniform folds\n",
    "block_labels = None  # Not needed for blocked splitting - useful for experiment-wise CV folds\n",
    "n_splits_outer = 4   # Four blocks for outer CV (must be larger than 1)\n",
    "n_splits_inner = 3   # Three blocks for inner CV (must be larger than 1)\n",
    "gap = 15 # number of TRs to skip/discard in between train and test to avoid leakage\n",
    "alphas = [0.1,1,10,100,1000,10000] # default vals from https://github.com/mtoneva/brain_language_nlp/blob/master/utils/utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0b0f8642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1211, 10240]), torch.Size([1211, 25263]))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1de37620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nested blocked cross-validation to find the best alpha per voxel for ridge regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Ridge Regression models fitted:   3%|▎         | 3/96 [00:29<15:07,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   6%|▋         | 6/96 [00:57<14:01,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:   9%|▉         | 9/96 [01:25<13:29,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  12%|█▎        | 12/96 [01:52<12:58,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  16%|█▌        | 15/96 [02:20<12:30,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  19%|█▉        | 18/96 [02:48<11:59,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([894, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(1, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  20%|█▉        | 19/96 [04:32<48:37, 37.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [-0.0332336  -0.07788308 -0.11560593 ...  0.00968779  0.05811946\n",
      "  0.01745196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  23%|██▎       | 22/96 [05:03<24:13, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  26%|██▌       | 25/96 [05:31<15:16, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  29%|██▉       | 28/96 [05:59<12:00, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  32%|███▏      | 31/96 [06:28<10:37,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  35%|███▌      | 34/96 [06:56<09:58,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  39%|███▊      | 37/96 [07:24<09:19,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(2, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  40%|███▉      | 38/96 [09:08<36:20, 37.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [ 0.05543184  0.08387576 -0.00931988 ...  0.01935829  0.05239794\n",
      "  0.04088382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  43%|████▎     | 41/96 [09:37<17:44, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  46%|████▌     | 44/96 [10:05<11:04, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  49%|████▉     | 47/96 [10:33<08:37, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  52%|█████▏    | 50/96 [11:02<07:28,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  55%|█████▌    | 53/96 [11:30<06:48,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  58%|█████▊    | 56/96 [11:58<06:16,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([879, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n",
      "Best alphas for fold: 25263 0 voxels with no best alpha found\n",
      "(3, 25263) best alphas shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  59%|█████▉    | 57/96 [13:31<22:29, 34.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer scores for this fold: [0.09816635 0.12470783 0.09702691 ... 0.02867154 0.08311213 0.10760191]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  62%|██████▎   | 60/96 [14:00<10:57, 18.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([891, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  66%|██████▌   | 63/96 [14:29<06:50, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([891, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  69%|██████▉   | 66/96 [14:57<05:14, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([891, 25263]) y_train_outer shape\n",
      "(25263,) best alphas for fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ridge Regression models fitted:  71%|███████   | 68/96 [15:16<04:39,  9.98s/it]"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "print(\"Starting nested blocked cross-validation to find the best alpha per voxel for ridge regression\")\n",
    "# Obtain the best ridge regression penalties for each voxel independently (~25k alphas)\n",
    "best_alphas, outer_scores = nested_blocked_cv(\n",
    "    X, y,\n",
    "    split_function=split_function,\n",
    "    block_labels=block_labels,\n",
    "    n_splits_outer=n_splits_outer,\n",
    "    n_splits_inner=n_splits_inner,\n",
    "    gap=gap,\n",
    "    alphas=alphas,\n",
    "    device=device\n",
    ")\n",
    "print(\"Best alphas found:\", best_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_labels = [[0 for _ in range(X.shape[0])]] # everything comes from the same story so we assume identical block_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391a772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db78f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.5 ('llms')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d70b9c756d066dea35eff74a2a233f0a1ea2f77535d9818d5bacdc123772e025"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
