{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f406b6-c855-4268-8ab0-a5948c35514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import cortex\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a426a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_VALUE_THRESHOLD = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b905553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaces = dict(\n",
    "# F = 'fMRI_story_F',\n",
    "# G = 'fMRI_story_G',\n",
    "# H = 'fMRI_story_H',\n",
    "I = 'fMRI_story_I',\n",
    "# J = 'fMRI_story_J',\n",
    "# K = 'fMRI_story_K',\n",
    "# L = 'fMRI_story_L',\n",
    "# M = 'fMRI_story_M',\n",
    "# N = 'fMRI_story_N'\n",
    ")\n",
    "\n",
    "transforms = dict(\n",
    "# F = 'F_ars',\n",
    "# G = 'G_ars',\n",
    "# H = 'H_ars',\n",
    "I = 'I_ars',\n",
    "# J = 'J_ars',\n",
    "# K = 'K_ars',\n",
    "# L = 'L_ars',\n",
    "# M = 'M_ars',\n",
    "# N = 'N_ars'\n",
    ")\n",
    "\n",
    "new_transforms = dict(\n",
    "# F = 'F_ars_auto2',\n",
    "# G = 'G_ars_auto2',\n",
    "# H = 'H_ars_auto2',\n",
    "I = 'I_ars_auto2',\n",
    "# J = 'J_ars_auto2',\n",
    "# K = 'K_ars_auto2',\n",
    "# L = 'L_ars_auto2',\n",
    "# M = 'M_ars_auto2',\n",
    "# N = 'N_ars_auto2'\n",
    ")\n",
    "\n",
    "sub = 'I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7723bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num voxels in new_transform for I: 25263\n"
     ]
    }
   ],
   "source": [
    "mask = cortex.db.get_mask(surfaces[sub], new_transforms[sub], 'thin')\n",
    "print('num voxels in new_transform for I: {}'.format(np.sum(mask)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e9fc3",
   "metadata": {},
   "source": [
    "## Setup results path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1ee875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = \"/Users/mosorio/Documents/CAJAL-NeuroAI/Project/cajal_llm_project/results/\"\n",
    "base_path = \"/Users/camilakolling/work/git/cajal_llm_project/results/\"\n",
    "\n",
    "experiment_name = \"shuffled_words/percentage0.25\"\n",
    "results_path = os.path.join(base_path, experiment_name)\n",
    "# experiment_name = \"shuffled_words/percentage0.5\"\n",
    "# experiment_name = \"shuffled_words/percentage1.0\"\n",
    "\n",
    "# experiment_name = \"shuffled_sentences/percentage0.25\"\n",
    "# experiment_name = \"shuffled_sentences/percentage0.5\"\n",
    "# experiment_name = \"shuffled_sentences/percentage1.0\"\n",
    "\n",
    "experiment_baseline_name = \"original_code\"\n",
    "results_baseline_path = os.path.join(base_path, experiment_baseline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320671c",
   "metadata": {},
   "source": [
    "## SHUFFLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4234202d-f9e8-4e84-975b-bd7b66920aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: Llama-3.2-1B-Full-Chapter\n",
      "Groups available: ['layer -7']\n",
      "Predictions shape: (300, 25263)\n"
     ]
    }
   ],
   "source": [
    "# Open in read mode\n",
    "with h5py.File(os.path.join(results_path, \"results_encoding_model.h5\"), 'r') as f:\n",
    "    # Read metadata\n",
    "    model_name = f.attrs['model_name']\n",
    "    print(\"Model name:\", model_name)\n",
    "\n",
    "    # List all groups\n",
    "    print(\"Groups available:\", list(f.keys()))\n",
    "\n",
    "    # Choose your group\n",
    "    representation_name = list(f.keys())[0]  # or set explicitly\n",
    "    group = f[representation_name]\n",
    "\n",
    "    # Read datasets\n",
    "    predictions = group['predictions'][:]\n",
    "    ground_truth = group['ground_truth'][:]\n",
    "    correlations = group['correlations'][:]\n",
    "    p_values = group['p_values'][:]\n",
    "    coefficients = group['coefficients'][:]\n",
    "    alphas = group['alphas'][:]\n",
    "\n",
    "    print(\"Predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ad951",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_values, _, _ = multipletests(p_values, alpha=P_VALUE_THRESHOLD, method=\"fdr_bh\")  # 'holm' for Holm-Bonferroni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3eeaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.05976337)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c41687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2003)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(correlations > 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddf158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25263,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# significant_voxels = np.where(p_values < P_VALUE_THRESHOLD, voxel_values_to_plot, 0.)\n",
    "significant_voxels = copy.deepcopy(correlations)\n",
    "significant_voxels[p_values > P_VALUE_THRESHOLD] = 0\n",
    "significant_voxels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b3819",
   "metadata": {},
   "source": [
    "## BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fe31b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: Llama-3.2-1B-Full-Chapter\n",
      "Groups available: ['layer -7']\n",
      "Predictions shape: (300, 25263)\n"
     ]
    }
   ],
   "source": [
    "# Open in read mode\n",
    "with h5py.File(os.path.join(results_baseline_path, \"results_encoding_model.h5\"), 'r') as f:\n",
    "    # Read metadata\n",
    "    model_name_baseline = f.attrs['model_name']\n",
    "    print(\"Model name:\", model_name_baseline)\n",
    "\n",
    "    # List all groups\n",
    "    print(\"Groups available:\", list(f.keys()))\n",
    "\n",
    "    # Choose your group\n",
    "    representation_name_baseline = list(f.keys())[0]  # or set explicitly\n",
    "    group = f[representation_name_baseline]\n",
    "\n",
    "    # Read datasets\n",
    "    predictions_baseline = group['predictions'][:]\n",
    "    ground_truth_baseline = group['ground_truth'][:]\n",
    "    correlations_baseline = group['correlations'][:]\n",
    "    p_values_baseline = group['p_values'][:]\n",
    "    coefficients_baseline = group['coefficients'][:]\n",
    "    alphas_baseline = group['alphas'][:]\n",
    "\n",
    "    print(\"Predictions shape:\", predictions_baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_values_baseline, _, _ = multipletests(p_values_baseline, alpha=P_VALUE_THRESHOLD, method=\"fdr_bh\")  # 'holm' for Holm-Bonferroni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec9e45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.12602845),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations_baseline.mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e6ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25263,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# significant_voxels = np.where(p_values < P_VALUE_THRESHOLD, voxel_values_to_plot, 0.)\n",
    "significant_voxels_baseline = copy.deepcopy(correlations_baseline)\n",
    "significant_voxels_baseline[p_values_baseline > P_VALUE_THRESHOLD] = 0\n",
    "significant_voxels_baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c595a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_values_baseline, _, _ = multipletests(p_values_baseline, alpha=P_VALUE_THRESHOLD, method=\"fdr_bh\")  # 'holm' for Holm-Bonferroni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e16e6",
   "metadata": {},
   "source": [
    "## DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2052d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_corr = correlations_baseline - correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82848af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6616530418395996"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_baseline=float(significant_voxels_baseline.max())\n",
    "max_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1458eb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_voxels_with_nan = significant_voxels.astype(float)\n",
    "significant_voxels_with_nan[significant_voxels_with_nan == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55023346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server on port 62293\n",
      "Stopping server\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<JS: window.viewer>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = cortex.Volume(significant_voxels_with_nan, surfaces[sub], new_transforms[sub], vmin=0, vmax=max_baseline, cmap='viridis')\n",
    "cortex.webshow(vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11182bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cajal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
